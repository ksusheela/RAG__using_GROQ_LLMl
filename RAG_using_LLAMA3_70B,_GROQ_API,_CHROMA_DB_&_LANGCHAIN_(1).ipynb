{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "054b19e878f34d08a60c404afeba7e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43967d6a42c46c6931e9e9f202ceca9",
              "IPY_MODEL_2aa37cff55f9481090a36c66cd86b6b1",
              "IPY_MODEL_4490c34a4edc429980f995718bc057dd"
            ],
            "layout": "IPY_MODEL_3cd837aeb63144fe9aa9dd64b7376f93"
          }
        },
        "c43967d6a42c46c6931e9e9f202ceca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10fb1ab628dd4747867a5656aa2a743d",
            "placeholder": "​",
            "style": "IPY_MODEL_408231f820f146a2ae298f7604111bef",
            "value": "modules.json: 100%"
          }
        },
        "2aa37cff55f9481090a36c66cd86b6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e58fc6d028264601acf6290e413cee98",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e6adc5513ce4677a870d4d19e22eb21",
            "value": 349
          }
        },
        "4490c34a4edc429980f995718bc057dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff75ae816e54569911437cf8c8b5834",
            "placeholder": "​",
            "style": "IPY_MODEL_ab051f52250d4705b22f0cdd7685209c",
            "value": " 349/349 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "3cd837aeb63144fe9aa9dd64b7376f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10fb1ab628dd4747867a5656aa2a743d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408231f820f146a2ae298f7604111bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e58fc6d028264601acf6290e413cee98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e6adc5513ce4677a870d4d19e22eb21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ff75ae816e54569911437cf8c8b5834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab051f52250d4705b22f0cdd7685209c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b13e0d4a86042489b46efbd0e3be2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c0a3688bf3d441abd58a0e99ca87cee",
              "IPY_MODEL_cd9d7225386140579e3f0292be3df4b6",
              "IPY_MODEL_1ba0cdff0a434502a038a646da489e0f"
            ],
            "layout": "IPY_MODEL_492540531def4ea28bb5986411ce2c03"
          }
        },
        "1c0a3688bf3d441abd58a0e99ca87cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb549c60448645d7b31ffa8110a315ba",
            "placeholder": "​",
            "style": "IPY_MODEL_74baeabc938c4e04931b845d489a29bc",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "cd9d7225386140579e3f0292be3df4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d376c01b7744902acf98ae3e0770d9f",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15c13e8dc56c408697428d418d269324",
            "value": 116
          }
        },
        "1ba0cdff0a434502a038a646da489e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_278f92b8d8174d0e8677842765b371f9",
            "placeholder": "​",
            "style": "IPY_MODEL_9f5b988caeb54074bd125390c8bad701",
            "value": " 116/116 [00:00&lt;00:00, 9.37kB/s]"
          }
        },
        "492540531def4ea28bb5986411ce2c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb549c60448645d7b31ffa8110a315ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74baeabc938c4e04931b845d489a29bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d376c01b7744902acf98ae3e0770d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c13e8dc56c408697428d418d269324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "278f92b8d8174d0e8677842765b371f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5b988caeb54074bd125390c8bad701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df9fcdacd5d4fe2b7f9b55ebce9cd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36092e4d6bfc48c8b2e58feaeec98689",
              "IPY_MODEL_8e9bc5f9cb61465abf3fa3a82a21912e",
              "IPY_MODEL_74f01b0454864e91ad0a17e433dd3796"
            ],
            "layout": "IPY_MODEL_9bf75a3d9c9448c3a99393547842ced9"
          }
        },
        "36092e4d6bfc48c8b2e58feaeec98689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcfb6014a7784f979ff39650f844f39a",
            "placeholder": "​",
            "style": "IPY_MODEL_5507c96fabc54def802dee1b309ad99d",
            "value": "README.md: 100%"
          }
        },
        "8e9bc5f9cb61465abf3fa3a82a21912e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c733e52103324671a33900a6f560bb54",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a825f9a445cc42cb99cc19421baa6b73",
            "value": 10621
          }
        },
        "74f01b0454864e91ad0a17e433dd3796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd70c19e1fd744919640a8a174b27533",
            "placeholder": "​",
            "style": "IPY_MODEL_43f18cd7ab76432abcdf72ceb790ce6a",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 578kB/s]"
          }
        },
        "9bf75a3d9c9448c3a99393547842ced9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfb6014a7784f979ff39650f844f39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5507c96fabc54def802dee1b309ad99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c733e52103324671a33900a6f560bb54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a825f9a445cc42cb99cc19421baa6b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd70c19e1fd744919640a8a174b27533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f18cd7ab76432abcdf72ceb790ce6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "767f76ec303245d38b6f7aaad09d07b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23b7920ad3664494bb818fc9204d9b98",
              "IPY_MODEL_4399fa3a3ae24e7f9116bb20c2d7139e",
              "IPY_MODEL_9b4c59d07f8f4d7592097b4aed055e74"
            ],
            "layout": "IPY_MODEL_39d4cdfc52584c348a2a145e51fcc810"
          }
        },
        "23b7920ad3664494bb818fc9204d9b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_025211a100e942d68e3dd637a30e1132",
            "placeholder": "​",
            "style": "IPY_MODEL_fda1d5d951044902bcd5816a69413bee",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "4399fa3a3ae24e7f9116bb20c2d7139e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb1e51675a545359aff9b446ee4962c",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3221e2bc7cb54485bcab3790be501a0d",
            "value": 53
          }
        },
        "9b4c59d07f8f4d7592097b4aed055e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf89b8cdc3cf43749682f2b6f4315c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_a6a033564fb24265a56c92d319d56454",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.89kB/s]"
          }
        },
        "39d4cdfc52584c348a2a145e51fcc810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "025211a100e942d68e3dd637a30e1132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda1d5d951044902bcd5816a69413bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eb1e51675a545359aff9b446ee4962c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3221e2bc7cb54485bcab3790be501a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf89b8cdc3cf43749682f2b6f4315c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a033564fb24265a56c92d319d56454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e49bc690841242a090597643834cbd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a01b9a8a10d48709b3850b40c4fb00c",
              "IPY_MODEL_76da0a010cbf43d98c2f2850b37bee2f",
              "IPY_MODEL_90d6c6a7184d488a9bfb72208e150a20"
            ],
            "layout": "IPY_MODEL_b10f8feae4104444bc9d3dc21032a4f6"
          }
        },
        "2a01b9a8a10d48709b3850b40c4fb00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e435fe7e3be648d7bb42255f63b16b8f",
            "placeholder": "​",
            "style": "IPY_MODEL_fd60f84b07d6439cac9cfe91bf1b91f7",
            "value": "config.json: 100%"
          }
        },
        "76da0a010cbf43d98c2f2850b37bee2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7dcd5310cf4c639eb948a18a69db33",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afb061d43e5844a48b063fbbf48675f6",
            "value": 571
          }
        },
        "90d6c6a7184d488a9bfb72208e150a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fa4cc4067e34009a6620a0ff4b17390",
            "placeholder": "​",
            "style": "IPY_MODEL_48caa172e13949258a2fc68083c26618",
            "value": " 571/571 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "b10f8feae4104444bc9d3dc21032a4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e435fe7e3be648d7bb42255f63b16b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd60f84b07d6439cac9cfe91bf1b91f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a7dcd5310cf4c639eb948a18a69db33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb061d43e5844a48b063fbbf48675f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fa4cc4067e34009a6620a0ff4b17390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48caa172e13949258a2fc68083c26618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a13c8d23004417ca73dff3c9b0e93c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3bdeddc09b74f14a0053283abc4c285",
              "IPY_MODEL_33d7df246667415e898ebcb279f8e04c",
              "IPY_MODEL_f7c821044fde44859fc30e91017c149c"
            ],
            "layout": "IPY_MODEL_fb5a94265ee64a518bdab4cf3d392757"
          }
        },
        "b3bdeddc09b74f14a0053283abc4c285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393450d260544e73a1cc39ee73608776",
            "placeholder": "​",
            "style": "IPY_MODEL_af70f049d30d4a569191c7816fe2aed8",
            "value": "model.safetensors: 100%"
          }
        },
        "33d7df246667415e898ebcb279f8e04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_002b81f739f94801bc7d271ea9fc2052",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_300c76c1a79b4221880a208d14336c94",
            "value": 437971872
          }
        },
        "f7c821044fde44859fc30e91017c149c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3842a449febc45cf9fbf8cc7034ee2f8",
            "placeholder": "​",
            "style": "IPY_MODEL_2ecc5968d85a49b0ace2d78268ad9769",
            "value": " 438M/438M [00:01&lt;00:00, 241MB/s]"
          }
        },
        "fb5a94265ee64a518bdab4cf3d392757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393450d260544e73a1cc39ee73608776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af70f049d30d4a569191c7816fe2aed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "002b81f739f94801bc7d271ea9fc2052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "300c76c1a79b4221880a208d14336c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3842a449febc45cf9fbf8cc7034ee2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecc5968d85a49b0ace2d78268ad9769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fefb3351baa440f2b33eca55b7250af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bca667cb27684f8ea763c7c90bfd802a",
              "IPY_MODEL_b42493bd2b364e10818192fdbd478d04",
              "IPY_MODEL_cddec9faecaa4414a4370c1962cd9d71"
            ],
            "layout": "IPY_MODEL_4b6f22c97643411996d6c5eab51baef7"
          }
        },
        "bca667cb27684f8ea763c7c90bfd802a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1618c202988643d1b82c624540390a98",
            "placeholder": "​",
            "style": "IPY_MODEL_20b56c292a9144218a84d8da1c2caba0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b42493bd2b364e10818192fdbd478d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd018eb6404092b4c798353ba248f2",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10fd72883e224b16b9b44acd42cb9988",
            "value": 363
          }
        },
        "cddec9faecaa4414a4370c1962cd9d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3059179fb6f24e5885fa71f1335fdeca",
            "placeholder": "​",
            "style": "IPY_MODEL_e83e9bd3e98d47ecb6895a52f58467b8",
            "value": " 363/363 [00:00&lt;00:00, 24.9kB/s]"
          }
        },
        "4b6f22c97643411996d6c5eab51baef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1618c202988643d1b82c624540390a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b56c292a9144218a84d8da1c2caba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11cd018eb6404092b4c798353ba248f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10fd72883e224b16b9b44acd42cb9988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3059179fb6f24e5885fa71f1335fdeca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e83e9bd3e98d47ecb6895a52f58467b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233e89b1cc2e4bf897c38588988d8f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a83aa67eed2f495eb226a422ec5fd350",
              "IPY_MODEL_561cd6a61d8b475ab49f9eb8636fdbf7",
              "IPY_MODEL_997c2c8206db49b4aadd625df9c9cdca"
            ],
            "layout": "IPY_MODEL_c925cf6c6d9440b7872ee72f1d02ff97"
          }
        },
        "a83aa67eed2f495eb226a422ec5fd350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7375b383a317403e8ad1f7347c81b8e7",
            "placeholder": "​",
            "style": "IPY_MODEL_00fe5d4b166344308c1ced9d67928989",
            "value": "vocab.txt: 100%"
          }
        },
        "561cd6a61d8b475ab49f9eb8636fdbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb5352d7cfd48efae5dd566c06091e4",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f5d48b7f424e0b9fda0662acd774b6",
            "value": 231536
          }
        },
        "997c2c8206db49b4aadd625df9c9cdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ddf6ca834ed4571b3e5c06b4bc42403",
            "placeholder": "​",
            "style": "IPY_MODEL_2fb4aa47ce994af7a00ef0e141185eae",
            "value": " 232k/232k [00:00&lt;00:00, 3.63MB/s]"
          }
        },
        "c925cf6c6d9440b7872ee72f1d02ff97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7375b383a317403e8ad1f7347c81b8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00fe5d4b166344308c1ced9d67928989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb5352d7cfd48efae5dd566c06091e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f5d48b7f424e0b9fda0662acd774b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ddf6ca834ed4571b3e5c06b4bc42403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb4aa47ce994af7a00ef0e141185eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d78cb730306040ad94eaa2e4ec330802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e6130c98feb4d1eae43a9f25456518f",
              "IPY_MODEL_485bb940051c4cb09074a804e152bd98",
              "IPY_MODEL_3f2a9bbf948049ebb6389dfb7c1f440a"
            ],
            "layout": "IPY_MODEL_7c940ff4011b420e8c260430544a6319"
          }
        },
        "9e6130c98feb4d1eae43a9f25456518f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a8443d1835b4b23ba1a83c166d6ae45",
            "placeholder": "​",
            "style": "IPY_MODEL_54b3faa040d2403699a6b5d91175bb4e",
            "value": "tokenizer.json: 100%"
          }
        },
        "485bb940051c4cb09074a804e152bd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f0c0a1994aa469698263fae9a3d9025",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb9f53f4d20046f99c737603c598c13e",
            "value": 466021
          }
        },
        "3f2a9bbf948049ebb6389dfb7c1f440a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d44e64ce504266b9e0d353afcb174d",
            "placeholder": "​",
            "style": "IPY_MODEL_ade70fd2b729450198adaf6c200ad7a2",
            "value": " 466k/466k [00:00&lt;00:00, 3.38MB/s]"
          }
        },
        "7c940ff4011b420e8c260430544a6319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8443d1835b4b23ba1a83c166d6ae45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54b3faa040d2403699a6b5d91175bb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f0c0a1994aa469698263fae9a3d9025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9f53f4d20046f99c737603c598c13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0d44e64ce504266b9e0d353afcb174d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade70fd2b729450198adaf6c200ad7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47b5b7f8d19f43f48d27311dc46a9b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b983ba645bf549048e0a531822932302",
              "IPY_MODEL_9eca31836e414e2dbf7c7d8fe0803d0c",
              "IPY_MODEL_1ff263affde3482395008600f7fdc458"
            ],
            "layout": "IPY_MODEL_9b2e087124f64883ad02f823b1daf5f4"
          }
        },
        "b983ba645bf549048e0a531822932302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1c670ba8d8e480f91b4e945c7541aec",
            "placeholder": "​",
            "style": "IPY_MODEL_20d9b94c9dd5403d898a1bde5148460a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9eca31836e414e2dbf7c7d8fe0803d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3595ef4c65bc46ea9e1e274f13e0f5ce",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9e24886b9ee4704841a6a7b48be64d4",
            "value": 239
          }
        },
        "1ff263affde3482395008600f7fdc458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce93db606ff484a82af219b1f644013",
            "placeholder": "​",
            "style": "IPY_MODEL_d3d1ad41ffea40f2bacea013ce3a7da3",
            "value": " 239/239 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "9b2e087124f64883ad02f823b1daf5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c670ba8d8e480f91b4e945c7541aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d9b94c9dd5403d898a1bde5148460a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3595ef4c65bc46ea9e1e274f13e0f5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e24886b9ee4704841a6a7b48be64d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fce93db606ff484a82af219b1f644013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d1ad41ffea40f2bacea013ce3a7da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8990c8c02ed4e7eb4329d556589ca58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ef590bd5c144cd0aa79a35e7ff2eda7",
              "IPY_MODEL_d54accf7e1774e3dbc23d569c3b02f4e",
              "IPY_MODEL_32015f22756e48a883414eeac9c01140"
            ],
            "layout": "IPY_MODEL_deea1d70782b4eba97ffa5a36c459cd5"
          }
        },
        "0ef590bd5c144cd0aa79a35e7ff2eda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afdcc89424541db926991f0886a3f72",
            "placeholder": "​",
            "style": "IPY_MODEL_d4f81806f5bb4d2f883c843cb39de543",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "d54accf7e1774e3dbc23d569c3b02f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a3982b8bc14c6982c10fdc9adb5245",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e497d4a16eb4a7eb11280b82bd8afcc",
            "value": 190
          }
        },
        "32015f22756e48a883414eeac9c01140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6633869ee043eeb75b6d55ee773d46",
            "placeholder": "​",
            "style": "IPY_MODEL_2dcd76439cbd4cad90ad6d0a9e66caa4",
            "value": " 190/190 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "deea1d70782b4eba97ffa5a36c459cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afdcc89424541db926991f0886a3f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f81806f5bb4d2f883c843cb39de543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a3982b8bc14c6982c10fdc9adb5245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e497d4a16eb4a7eb11280b82bd8afcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a6633869ee043eeb75b6d55ee773d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcd76439cbd4cad90ad6d0a9e66caa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P8SF3_Qpapt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3a498d-9a1e-4a5c-cd30-edcd4d35f656"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "IFaFceUZlts3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.5.5 langchain-chroma==0.1.2 langchain==0.2.11 langchain-community==0.2.10 langchain-text-splitters==0.2.2 langchain-groq==0.1.6 transformers==4.43.2 sentence-transformers==3.0.1 unstructured==0.15.0 unstructured[pdf]==0.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzSCCx9clz1c",
        "outputId": "1ee110d5-a6e2-42f3-eda1-4f6ade615591",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb==0.5.5 in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: langchain-chroma==0.1.2 in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: langchain==0.2.11 in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
            "Requirement already satisfied: langchain-community==0.2.10 in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: langchain-text-splitters==0.2.2 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain-groq==0.1.6 in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: transformers==4.43.2 in /usr/local/lib/python3.10/dist-packages (4.43.2)\n",
            "Requirement already satisfied: sentence-transformers==3.0.1 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: unstructured==0.15.0 in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (2.9.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (0.34.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (3.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.5) (0.28.1)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma==0.1.2) (0.2.43)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (4.0.3)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (0.1.147)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.11) (2.32.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.10) (0.6.7)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq==0.1.6) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.2) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.0.1) (11.0.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (5.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (3.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (2.14.0)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (2024.10.22)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (3.11.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (0.28.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured==0.15.0) (5.9.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (1.17.0)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (1.17.0)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (20231228)\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (9.4.2)\n",
            "Requirement already satisfied: pillow-heif in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.21.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (5.1.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.3.13)\n",
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (3.9.0)\n",
            "Requirement already satisfied: effdet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.4.1)\n",
            "Requirement already satisfied: unstructured-inference==0.7.36 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.7.36)\n",
            "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]==0.15.0) (0.3.13)\n",
            "Requirement already satisfied: layoutparser in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.3.4)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.0.20)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (3.8.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (1.0.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.11) (1.18.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.5) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.5) (2.2.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.5.5) (0.41.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.1.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.1.6) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq==0.1.6) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb==0.5.5) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb==0.5.5) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb==0.5.5) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.5) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.2) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.5) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.2) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.11) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (5.29.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.5) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.5) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.5) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.5) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (0.50b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.5) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.5.5) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.5.5) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.5.5) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.11) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.11) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.0.1) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.5) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.5) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.5) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.5) (13.9.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.5) (14.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.15.0) (2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]==0.15.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]==0.15.0) (2.0.8)\n",
            "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.10/dist-packages (from effdet->unstructured[pdf]==0.15.0) (2.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]==0.15.0) (2.19.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[pdf]==0.15.0) (1.25.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.15.0) (1.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]==0.15.0) (43.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.0.1) (3.5.0)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (24.1.0)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (0.2.0)\n",
            "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (1.0.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.15.0) (1.6.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq==0.1.6) (1.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]==0.15.0) (1.17.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]==0.15.0) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.5) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain-chroma==0.1.2) (3.0.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]==0.15.0) (4.9.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (3.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.5) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.0.1) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (2.2.2)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.1.10)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (0.11.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]==0.15.0) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.5.5) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.5) (0.6.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (2024.2)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.36->unstructured[pdf]==0.15.0) (4.30.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3npbSnkEOnI"
      },
      "outputs": [],
      "source": [
        "#!pip install -r requirment.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "dnXdBXobJ6V4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://groq.com/ Create GROQ API KEY"
      ],
      "metadata": {
        "id": "soVlC8lHpUvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "AYisSusDJ6YT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGk3eCbOnlBL",
        "outputId": "7625db67-cada-478f-9f9e-d4400a1ce835"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PyPDF2 import PdfReader\n",
        "from io import BytesIO\n",
        "\n",
        "# URL of the PDF\n",
        "url = \"https://arxiv.org/pdf/2412.14581.pdf\"\n",
        "\n",
        "# Fetch the PDF from the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Load PDF from bytes\n",
        "    pdf_file = BytesIO(response.content)\n",
        "    reader = PdfReader(pdf_file)\n",
        "\n",
        "    # Extract text from each page\n",
        "    documents = [page.extract_text() for page in reader.pages]\n",
        "    print(\"\\n\".join(documents))  # Print the extracted text\n",
        "else:\n",
        "    print(f\"Failed to fetch the PDF. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "zvhSfiklOe5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301223df-9fe9-446e-c57f-d0a76213f3fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CORD: Balancing COnsistency and Rank Distillation\n",
            "for Robust Retrieval-Augmented Generation\n",
            "Youngwon Lee*Seung-won Hwang*Daniel Campos\n",
            "Filip Grali ´nski Zhewei Yao Yuxiong He\n",
            "Snowflake AI Research Seoul National University*\n",
            "Abstract\n",
            "With the adoption of retrieval-augmented gen-\n",
            "eration (RAG), large language models (LLMs)\n",
            "are expected to ground their generation to the\n",
            "retrieved contexts. Yet, this is hindered by posi-\n",
            "tion bias of LLMs, failing to evenly attend to all\n",
            "contexts. Previous work has addressed this by\n",
            "synthesizing contexts with perturbed positions\n",
            "of gold segment, creating a position-diversified\n",
            "train set. We extend this intuition to propose\n",
            "consistency regularization with augmentation\n",
            "and distillation. First, we augment each train-\n",
            "ing instance with its position perturbation to\n",
            "encourage consistent predictions, regardless of\n",
            "ordering. We also distill behaviors of this pair,\n",
            "although it can be counterproductive in certain\n",
            "RAG scenarios where the given order from the\n",
            "retriever is crucial for generation quality. We\n",
            "thus propose CORD, balancing COnsistency\n",
            "and Rank Distillation. CORD adaptively sam-\n",
            "ples noise-controlled perturbations from an in-\n",
            "terpolation space, ensuring both consistency\n",
            "and respect for the rank prior. Empirical results\n",
            "show this balance enables CORD to outperform\n",
            "consistently in diverse RAG benchmarks.\n",
            "1 Introduction\n",
            "Recently, large language models (LLMs) have in-\n",
            "corporated retrievers to augment input contexts\n",
            "for more grounded generation. However, during\n",
            "retrieval-augmented generation (RAG), LLMs re-\n",
            "portedly suffer from position bias where they pay\n",
            "disproportionate attention to different parts, wors-\n",
            "ened as the input becomes longer (Liu et al., 2024).\n",
            "An existing solution has synthesized a training set\n",
            "by randomizing the position of gold segment (An\n",
            "et al., 2024). It allows LLMs to implicitly learn\n",
            "that relevant information can appear at any position,\n",
            "mitigating position bias.\n",
            "Our distinction is to pursue dual goals of (1)\n",
            "COnsistency for mitigating position bias and (2)\n",
            "*Work done while visiting Snowflake. Correspondence to:\n",
            "seungwonh@snu.ac.kr .\n",
            "Figure 1: Enforcing consistency with (1) augmentation\n",
            "(green) and (2) distillation (blue).\n",
            "Method (A) (B)\n",
            "Given order 41.34 56.52\n",
            "+ consistency 36.87 ( Ó) 57.87 (Ò)\n",
            "CORD (ours) 44.74 (Ò)58.71 (Ò)\n",
            "Table 1: Representative RAG scenarios A and B, where\n",
            "distillation may hinder or enhance, respectively.\n",
            "RankDistillation, learning to utilize meaningful\n",
            "signals in the given order from the retriever and\n",
            "also to denoise it, for robust RAG.\n",
            "For CO, we extend the position-perturbing train-\n",
            "ing intuition, by augmenting the retriever-given\n",
            "order cwith its perturbation c1, sharing the same\n",
            "ground truth ˆy. Green arrows in Figure 1 visualize\n",
            "how this augmentation indirectly enforces consis-\n",
            "tency by guiding predictions yfrom candy1from\n",
            "c1, to converge to the ground-truth ˆy.\n",
            "Another more direct approach is adding a distilla-\n",
            "tion loss penalizing the distributional divergence in\n",
            "all outputs. The blue arrow in Figure 1 visualizes\n",
            "this loss further incentivizing consistent internal\n",
            "representation, by distilling ‘dark knowledge’ (Hin-\n",
            "ton et al., 2015; Sadowski et al., 2015; Furlanello\n",
            "et al., 2018) from one to another.\n",
            "However, pursuing CO objective alone, without\n",
            "balancing it with the RD objective, is counterpro-\n",
            "ductive in some scenarios as illustrated in Table 1.\n",
            "It contrasts two representative real-life RAG sce-\n",
            "narios A and B:1In A, retriever provides a reliable\n",
            "rank prior, such that distilling predictions from a\n",
            "1For presentation brevity, we reveal in later section.\n",
            "1arXiv:2412.14581v1  [cs.CL]  19 Dec 2024\n",
            "Figure 2: (Left) IN2only uses c1. (Right) We augment\n",
            "the given order c(top) with perturbed ranking c1(bot-\n",
            "tom) and use both.\n",
            "randomized ordering can unlearn this helpful prior,\n",
            "as evidenced by a decrease in generation quality\n",
            "after consistency regularization. Meanwhile, in B,\n",
            "where generation is not sensitive to the given order,\n",
            "CO objective enhances performance.\n",
            "Our technical contribution is to adapt c1to the\n",
            "given scenario, by controlling the degree of pertur-\n",
            "bation, in place of c1with a fixed randomization.\n",
            "We define an interpolated space of perturbations\n",
            "and dynamically sample an appropriate level of\n",
            "perturbation from it. Table 1 shows CORD out-\n",
            "performs in both scenarios, by sampling smaller\n",
            "perturbations in scenario A, where rank prior is\n",
            "important, and larger perturbations in scenario B,\n",
            "where robustness to position bias is crucial.\n",
            "Our contribution can be summarized as follows:\n",
            "(1) We propose CORD , balancing connsistency\n",
            "and rank distillation in RAG. (2) We show distill-\n",
            "ing with a controlled perturbation, sampled from\n",
            "an interpolated space of teachers, is effective across\n",
            "5 diverse RAG scenarios, whereas existing consis-\n",
            "tency methods fall short.\n",
            "2 Method\n",
            "2.1 CO: Consistency regularization\n",
            "We propose to mitigate position bias by regulariz-\n",
            "ing output consistency over possible perturbations,\n",
            "through (1) augmentation and (2) distill loss.\n",
            "First, we explain how augmenting position-\n",
            "perturbed examples contributes to consistency. We\n",
            "first formalize RAG as generating an answer y\n",
            "given an input x,\n",
            "y„pp¨|x,cq, (1)\n",
            "along with the sequence of nretrieved contexts\n",
            "c“ rc1;c2;¨¨¨;cns. Then, for a training triplet\n",
            "px,c,ˆyqthe negative log-likelihood (NLL) loss for\n",
            "maximum likelihood estimation training is\n",
            "Ln“´ÿ\n",
            "tlogppˆyt|x,c,ˆyătq, (2)\n",
            "which encourages the model to produce the correct\n",
            "answer ˆygiven the input xand retrieved contexts.Inspired by An et al. (2024), referred to as IN2,\n",
            "we employ position perturbation to augment cfrom\n",
            "the corpus Cwith c1. For comparison, IN2synthe-\n",
            "sized question and context pq,cqpairs where the\n",
            "gold passage sfor generating the gold answer ˆy\n",
            "appears in various positions. As Figure 2 shows,\n",
            "we retain both the original pq,c,ˆyqand the per-\n",
            "turbed examples pq,c1,ˆyq: Unlike IN2’s using c1\n",
            "only for training (orange arrows), we train over the\n",
            "augmented dataset C1which includes both candc1\n",
            "(blue arrows). Predictions for both are supervised\n",
            "to converge to the same ground-truth ˆyusing the\n",
            "loss in Eq 2.\n",
            "Second, by adding a distill loss, we can further\n",
            "match token-level output probability distributions\n",
            "forcandc1. We use the sum of Jensen-Shannon\n",
            "Divergence (JSD) between output probability dis-\n",
            "tributions at each time step tfor this purpose:2\n",
            "Ld“ÿ\n",
            "tJSD`\n",
            "ftpcq}ftpc1q˘\n",
            ", (3)\n",
            "where ftpcq “ppˆyt|x,c,ˆyătq. This encourages\n",
            "the model to align its internal representations of in-\n",
            "put and association with the output, encoded in the\n",
            "‘dark knowledge’ (Hinton et al., 2015; Sadowski\n",
            "et al., 2015; Furlanello et al., 2018) across different\n",
            "perturbations.\n",
            "Finally, the two types of loss in Eq 2 and 3 can\n",
            "be combined to obtain our training objective:\n",
            "L“Ln`λ¨Ld, (4)\n",
            "where the hyperparameter λdetermines the relative\n",
            "strength of the two terms.\n",
            "2.2 RD: Adaptive teacher selection for rank\n",
            "distillation\n",
            "However, as previously outlined in Table 1A, dis-\n",
            "till loss on a random perturbation c1may inter-\n",
            "fere with the RD objective in an RAG scenario\n",
            "where retriever provides a meaningful ranking c\n",
            "with valuable prior: In this work, we consider MS\n",
            "MARCO (Bajaj et al., 2018) as a representative ex-\n",
            "ample, where an industry-scale complex retrieval\n",
            "system provides the ranking.\n",
            "Figure 3A depicts such unlearning of ranker\n",
            "prior, when distilled from a random perturbation\n",
            "in scenario A. The y-axis in the plot represents the\n",
            "probability the LLM assigns to the ground-truth an-\n",
            "swer, ppˆy|x,cqfor the given order c(solid circle)\n",
            "2While we default to summing all terms, the number of\n",
            "time steps tto aggregate in Eq 3 can be adjusted for efficiency,\n",
            "as detailed in Appendix C.\n",
            "2\n",
            "MS MARCO HotpotQA NQ MN MN-IDK\n",
            "Finetuning Objective R-L GPT-4 EM GPT-4 Acc GPT-4 F1 Acc\n",
            "No finetuning 41.34 51.94 42.86 66.50 52.18 62.46 56.52 54.82\n",
            "LnllonC144.52 57.28 58.62 83.75 55.60 63.51 56.25 95.78\n",
            "CORD 44.74 57.28 63.55 85.72 58.55 63.72 58.71 98.83\n",
            "Table 2: RAG performance with Phi-3 3B as the generator and different finetuning strategies applied.\n",
            "Figure 3: Interpolated sample space for scenario A and\n",
            "B from Table 1, where (A, left) perturbation leads to\n",
            "a large drop in probability of ground-truth ˆy, and (B,\n",
            "right) with no such drop.\n",
            "andppˆy|x,c1qfor random perturbation c1(empty\n",
            "circle). In MS MARCO, the given order ccar-\n",
            "ries a useful prior, resulting in high probability of\n",
            "the ground-truth ppˆy|x,cq. Randomizing this or-\n",
            "der would greatly lower the probability ppˆy|x,c1q,\n",
            "such that enforcing consistency between the two\n",
            "would unlearn the benefit of rank prior.\n",
            "To tackle this, instead of fixing c1as a random\n",
            "perturbation, we define a sample space and strategy\n",
            "for adaptive teacher selection, to control the degree\n",
            "of perturbation for distillation. We introduce an\n",
            "interpolation of candc1with a controlled noise\n",
            "degree of α, denoted as c1\n",
            "α: Here, the lower ranked\n",
            "αproportion of the retrieved contexts is random-\n",
            "ized while the remaining retains the given order. In\n",
            "Figure 3, such interpolated sample is shown as a\n",
            "shaded circle on a dotted line, the interpolated path\n",
            "connecting candc1, as the noise degree αvaries\n",
            "from 0 to 1. For brevity, we assume a desirable sin-\n",
            "gle value of αfor the given task is known a priori,\n",
            "and later discuss how to find it in Section 2.3.\n",
            "This interpolation allows to select a better\n",
            "teacher between c1\n",
            "αandc1by choosing the one\n",
            "with a higher probability of predicting the ground\n",
            "truth. As shown in Figure 3A, small perturbations\n",
            "tend to yield higher yvalues in scenario A as they\n",
            "retain the given order in part, leading to c1\n",
            "αchosen\n",
            "for distillation. This corresponds to ensembling\n",
            "two retrievers, which agree on top-ranked docu-\n",
            "ments but diversify the ranks of the rest.\n",
            "An added advantage is, the same approach seam-lessly supports scenario B, where there is no con-\n",
            "flict between CO and RD. As illustrated in Fig-\n",
            "ure 3B, the y-axis score remains relatively stable\n",
            "across different orderings, and moreover, the score\n",
            "is no longer sensitive to ordering. Thus, pairing the\n",
            "given order with the one that has a higher yscore\n",
            "essentially serves the goal of pursuing CO.\n",
            "2.3 Score-aware teacher sampling\n",
            "So far, we have mainly focused on utilizing rank\n",
            "prior from the retriever; however, the retriever may\n",
            "provide varying level of information in different\n",
            "RAG scenarios, such as score for each item as well.\n",
            "We describe how to incorporate such additional\n",
            "signals into adaptive teacher sampling.\n",
            "When no prior knowledge of the distribution of\n",
            "the probability of ground-truth ppˆy|x,c1\n",
            "αqover the\n",
            "interpolated path is known, we follow the princi-\n",
            "ple of maximum entropy (Jaynes, 1957) to assume\n",
            "uniform distribution. That is, we choose to sample\n",
            "α“0.5from the interpolated space defined in\n",
            "Section 2.2, where αvaries in the range of p0,1q.\n",
            "Alternatively, we utilize retriever scores as a\n",
            "proxy for the unknown distribution of ppˆy|x,c1\n",
            "αq,\n",
            "from which the optimal noise level αcan be de-\n",
            "termined. Specifically, we aim to extract the most\n",
            "confident top-ranked contexts identified by the re-\n",
            "triever, by preserving the contexts ranked above\n",
            "the largest discontinuity in scores and perturbing\n",
            "the rest. Given scores sifor each retrieved context\n",
            "ciPc, which are sorted in descending order of\n",
            "score, i.e., s1ąs2ą ¨¨¨ ą sn, we locate the\n",
            "adjacent pair of passages with the largest gap in\n",
            "retriever score ˆi“argmaxipsi´si`1qand per-\n",
            "turb the passages ranked lower than ˆi. In other\n",
            "words, we choose α“1´ˆi{nfor this example.\n",
            "Intuitively, this approximates finding the largest\n",
            "acceptable degree of noise that would still result in\n",
            "sufficiently high ppˆy|x,c1\n",
            "αq.\n",
            "3 Results\n",
            "We design evaluations to answer these research\n",
            "questions: (RQ1) Does CORD pursue dual goals\n",
            "3\n",
            "MS MARCO\n",
            "Finetuning Method R-L GPT-4\n",
            "No finetuning 41.34 51.94\n",
            "LnllonC 41.81 51.94\n",
            "LnllonC144.52 57.28\n",
            "CORD 44.74 57.28\n",
            "Table 3: Without augmentation (second row) there is a\n",
            "clear performance gap compared to models trained with\n",
            "consistency objectives (third and fourth row).\n",
            "MN MN-IDK\n",
            "Finetuning Method F1 Acc\n",
            "CORD 58.71 98.83\n",
            "+ Adaptive α 59.16 98.83\n",
            "Table 4: Effect of dynamically adjusting αbased on\n",
            "retriever score.\n",
            "of CO and RD effectively? (RQ2) Does CORD\n",
            "adaptively choose pc,c1qpair in different scenar-\n",
            "ios? (RQ3) How can the noise degree αfor inter-\n",
            "polation be tuned per task or example?\n",
            "3.1 Experimental settings\n",
            "We have evaluated our proposed method on several\n",
            "QA benchmarks: MS MARCO (Bajaj et al., 2018),\n",
            "HotpotQA (Yang et al., 2018), NaturalQuestions\n",
            "(Kwiatkowski et al. (2019); NQ) as reorganized by\n",
            "Liu et al. (2024). We further consider multi-needle\n",
            "(MN) dataset, which is built following An et al.\n",
            "(2024), as a scenario where irrelevant contexts are\n",
            "prevalent and retriever prior is not meaningful.3\n",
            "For evaluation, we used widely reported metrics\n",
            "for each benchmark, namely ROUGE-L for MS\n",
            "MARCO, exact match (EM) for HotpotQA, and\n",
            "span-based exact match, or ‘accuracy’ for NQ. We\n",
            "also adopted the evaluation protocol from Yang\n",
            "et al. (2024) using GPT-4, allowing more flexibil-\n",
            "ity in answers. For MN where answers typically\n",
            "contain a few sentences, we report sentence-level\n",
            "F1, and for MN-IDK, an unanswerable split of MN,\n",
            "we report accuracy. Further details can be found in\n",
            "Appendix B.\n",
            "3.2 Results\n",
            "Bias mitigation and rank distillation Table 2\n",
            "shows that our proposed method outperforms the\n",
            "baselines across all benchmarks, validating its ef-\n",
            "fectiveness in pursuing dual goals of CO and RD.\n",
            "In addition, Table 3 shows the importance of\n",
            "3This corresponds to scenario B in Table 1 and Figure 3.\n",
            "Figure 4: (Top) On MS MARCO, the interpolated noise-\n",
            "controlled perturbation c1\n",
            "α(dark blue) is much more\n",
            "likely to be paired with the given order c, than c1(light\n",
            "blue). (Bottom) The gap is much smaller on MN.\n",
            "denoising through consistency in rank distillation.\n",
            "There is a clear performance gap between the\n",
            "model trained on the given order cwithout aug-\n",
            "mentation (2nd row), and those augmented (3rd &\n",
            "4th) on MS MARCO. This suggests that even with\n",
            "a strong rank prior, consistency across slight pertur-\n",
            "bation positively contributes to RD, by mitigating\n",
            "potential bias from retriever or generator.\n",
            "Adaptive pair selection CORD indeed selects\n",
            "the proper teacher for enforcing consistency, while\n",
            "the tendency in choices exhibit clear difference\n",
            "per different RAG scenario, as shown in Figure 4.\n",
            "The ratio of c1\n",
            "αpaired with cis shown with dark\n",
            "blue, while the ratio of c1paired with cis presented\n",
            "by light blue bar. Comparing MS MARCO (top)\n",
            "and MN (bottom), it is clearly shown that c1\n",
            "αis\n",
            "much more likely to be paired with cin the former,\n",
            "where the RD objective is more prominent. This\n",
            "supports our rationale behind designing adaptive\n",
            "teacher selection in Section 2.2.\n",
            "Score-aware teacher sampling Table 4 shows\n",
            "that score-aware dynamic adjustment of α, de-\n",
            "scribed in Section 2.3 brings further gain; the effec-\n",
            "tive mean value of αthroughout the train set was\n",
            "0.8, suggesting a larger portion of the ranking was\n",
            "allowed to be perturbed.\n",
            "4 Conclusion\n",
            "We have presented CORD , to balance the tension\n",
            "between CO (consistency) and RD (rank distilla-\n",
            "tion) objectives in RAG. For the former, we aug-\n",
            "ment order-perturbed contexts and add distillation\n",
            "loss for explicit consistency regularization. For\n",
            "the latter, CORD adaptively chooses desirable de-\n",
            "gree of perturbation to prevent unlearning valuable\n",
            "prior from the retriever. CORD consistently outper-\n",
            "forms existing methods in diverse RAG scenarios.\n",
            "4\n",
            "Limitations\n",
            "Whether our findings generalize over diverse mod-\n",
            "els can be further explored. In addition, the pros\n",
            "and cons of diverse mixing strategies for an inter-\n",
            "polated sample space, such as employing another\n",
            "retriever for mix, can be explored; we leave it as\n",
            "future work.\n",
            "References\n",
            "Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng,\n",
            "and Jian-Guang Lou. 2024. Make your llm fully\n",
            "utilize the context. Preprint , arXiv:2404.16811.\n",
            "Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\n",
            "Jianfeng Gao, Xiaodong Liu, Rangan Majumder,\n",
            "Andrew McNamara, Bhaskar Mitra, Tri Nguyen,\n",
            "Mir Rosenberg, Xia Song, Alina Stoica, Saurabh\n",
            "Tiwary, and Tong Wang. 2018. Ms marco: A human\n",
            "generated machine reading comprehension dataset.\n",
            "Preprint , arXiv:1611.09268.\n",
            "Ching-Yao Chuang and Youssef Mroueh. 2021. Fair\n",
            "mixup: Fairness via interpolation. In 9th Inter-\n",
            "national Conference on Learning Representations,\n",
            "ICLR 2021, Virtual Event, Austria, May 3-7, 2021 .\n",
            "OpenReview.net.\n",
            "Yao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\n",
            "naneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\n",
            "Data engineering for scaling language models to 128k\n",
            "context. In Forty-first International Conference on\n",
            "Machine Learning, ICML 2024, Vienna, Austria, July\n",
            "21-27, 2024 . OpenReview.net.\n",
            "Tommaso Furlanello, Zachary Lipton, Michael Tschan-\n",
            "nen, Laurent Itti, and Anima Anandkumar. 2018.\n",
            "Born again neural networks. In Proceedings of the\n",
            "35th International Conference on Machine Learn-\n",
            "ing, volume 80 of Proceedings of Machine Learning\n",
            "Research , pages 1607–1616. PMLR.\n",
            "Geoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2015.\n",
            "Distilling the knowledge in a neural network. In\n",
            "NIPS Deep Learning and Representation Learning\n",
            "Workshop .\n",
            "E. T. Jaynes. 1957. Information theory and statistical\n",
            "mechanics. Phys. Rev. , 106:620–630.\n",
            "Rohan Jha, Bo Wang, Michael Günther, Saba Sturua,\n",
            "Mohammad Kalim Akram, and Han Xiao. 2024.\n",
            "Jina-colbert-v2: A general-purpose multilingual late\n",
            "interaction retriever. CoRR , abs/2408.16672.\n",
            "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\n",
            "field, Michael Collins, Ankur Parikh, Chris Alberti,\n",
            "Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\n",
            "ton Lee, Kristina Toutanova, Llion Jones, Matthew\n",
            "Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\n",
            "Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\n",
            "ral questions: A benchmark for question answeringresearch. Transactions of the Association for Compu-\n",
            "tational Linguistics , 7:452–466.\n",
            "Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu,\n",
            "Nouha Dziri, Melanie Sclar, Khyathi Chandu, Chan-\n",
            "dra Bhagavatula, and Yejin Choi. 2024. The unlock-\n",
            "ing spell on base llms: Rethinking alignment via\n",
            "in-context learning. In International Conference on\n",
            "Learning Representations .\n",
            "Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\n",
            "jape, Michele Bevilacqua, Fabio Petroni, and Percy\n",
            "Liang. 2024. Lost in the middle: How language mod-\n",
            "els use long contexts. Transactions of the Association\n",
            "for Computational Linguistics , 12:157–173.\n",
            "Peter Sadowski, Julian Collado, Daniel Whiteson, and\n",
            "Pierre Baldi. 2015. Deep learning, dark knowl-\n",
            "edge, and dark matter. In Proceedings of the NIPS\n",
            "2014 Workshop on High-energy Physics and Ma-\n",
            "chine Learning , volume 42 of Proceedings of Ma-\n",
            "chine Learning Research , pages 81–87, Montreal,\n",
            "Canada. PMLR.\n",
            "Qizhe Xie, Zihang Dai, Eduard H. Hovy, Thang Luong,\n",
            "and Quoc Le. 2020. Unsupervised data augmenta-\n",
            "tion for consistency training. In Advances in Neural\n",
            "Information Processing Systems 33: Annual Confer-\n",
            "ence on Neural Information Processing Systems 2020,\n",
            "NeurIPS 2020, December 6-12, 2020, virtual .\n",
            "Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla,\n",
            "Xiangsen Chen, Sajal Choudhary, Rongze Daniel\n",
            "Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong,\n",
            "Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan,\n",
            "Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang,\n",
            "Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah,\n",
            "Rakesh Wanga, Anuj Kumar, Wen-tau Yih, and\n",
            "Xin Luna Dong. 2024. CRAG - comprehensive RAG\n",
            "benchmark. CoRR , abs/2406.04744.\n",
            "Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\n",
            "William Cohen, Ruslan Salakhutdinov, and Christo-\n",
            "pher D. Manning. 2018. HotpotQA: A dataset for\n",
            "diverse, explainable multi-hop question answering.\n",
            "InProceedings of the 2018 Conference on Empiri-\n",
            "cal Methods in Natural Language Processing , pages\n",
            "2369–2380, Brussels, Belgium. Association for Com-\n",
            "putational Linguistics.\n",
            "5\n",
            "A Related Work\n",
            "A.1 Position bias in long context LLM\n",
            "Liu et al. (2024) and similar works have shown that\n",
            "LLMs favor input contexts placed at the beginning\n",
            "or end of the input, a tendency that benchmarks\n",
            "like needle-in-a-haystack4aim to assess by testing\n",
            "their ability to locate relevant information (‘nee-\n",
            "dle’) within long, potentially irrelevant contexts\n",
            "(‘haystack’). An et al. (2024) extended this un-\n",
            "derstanding by training models on synthetic data,\n",
            "intentionally perturbing a position of gold segment\n",
            "and adding random noises. Similarly, Fu et al.\n",
            "(2024) examined continual pretraining of LLMs\n",
            "on long-context data to expand their context win-\n",
            "dow size for retrieving information.\n",
            "Our distinction is to use position perturbation\n",
            "for a different objective of data augmentation for\n",
            "consistency training.\n",
            "A.2 Data augmentation for consistency\n",
            "Pairing a datapoint with a counterfactual applying\n",
            "a small perturbation has been mainly studied for\n",
            "robust training on simpler tasks such as classifica-\n",
            "tion (Xie et al., 2020). To our knowledge, we are\n",
            "the first to augment a position-perturbed retriever\n",
            "during training and enforce consistency for RAG.\n",
            "Another related line of work is interpolating\n",
            "two training instances (Chuang and Mroueh, 2021),\n",
            "which we extend to define a space of controlled per-\n",
            "turbations for dynamic adaptation in Section 2.2.\n",
            "B Implementation Details\n",
            "MN construction For MN data construction, we\n",
            "generally followed the recipe from An et al. (2024),\n",
            "with the subtle difference that Mixtral was used for\n",
            "question and answer generation. When preparing\n",
            "the MN dataset following An et al. (2024), we gen-\n",
            "erally abide by their practices, while using Mixtral\n",
            "as the LLM for question and answer extraction, and\n",
            "employed GPT-4 to verify it. For the seed corpus,\n",
            "we utilized the same realnewslike subset from\n",
            "the C4 corpus as C. We refer the reader to their\n",
            "original paper for more details.\n",
            "In addition, to study how LLMs can be trained\n",
            "to refuse to answer when there are insufficient evi-\n",
            "dence provided, rather than to hallucinate, we split\n",
            "the test set into two settings, answerable and unan-\n",
            "swerable: In the latter, dubbed MN-IDK, the gold\n",
            "segment sthat provides the evidence to answer the\n",
            "4github.com/gkamradt/LLMTest_NeedleInAHaystackgiven question is omitted. Thus, the model is ex-\n",
            "pected to answer it does not have enough evidence\n",
            "in the contexts to provide the correct answer, or, ‘I\n",
            "don’t know.’\n",
            "Metrics The evaluation protocol involving GPT-\n",
            "4 as the judge from Yang et al. (2024) evaluates\n",
            "the correctness of the answer with greater flexibil-\n",
            "ity, compared to the canonical lexical match based\n",
            "metrics, and is known to align better with human\n",
            "judgment. Also, it penalizes hallucinated response\n",
            "more than simply abstaining.\n",
            "While other benchmarks considered in this work\n",
            "require shorter answers, expected answers in MN\n",
            "and MN-IDK typically comprise of a few sentences:\n",
            "thus, we report sentence-level F1 score for MN,\n",
            "where GPT-4 was used as a judge in the same man-\n",
            "ner as the method described above to decide each\n",
            "sentence in the generated answer is supported by\n",
            "the ground-truth (precision), and vice versa (re-\n",
            "call). For MN-IDK, GPT-4 determined whether the\n",
            "model response successfully refused to provide the\n",
            "answer or not, and we reported the accuracy.\n",
            "Training For MS MARCO, HotpotQA and MN,\n",
            "we finetuned Phi-3 3B model on their respective\n",
            "train data: for MS MARCO, we used 20k examples\n",
            "held out from v2.1 dev set for training, and used\n",
            "non-overlapping subset for testing.\n",
            "For training with CORD on MN, as described in\n",
            "Section 2.2, we generated an artificial ranking over\n",
            "the passages by reranking them with a ColBERT\n",
            "variant model from Jina AI,56which also provided\n",
            "scores for each passage. This artificial ranking\n",
            "serves as the opposite extreme of the interpolated\n",
            "perturbation space, c1.\n",
            "The base model, Phi-3 3B, was trained with\n",
            "LoRA at bf16 precision. The relevant hyperparame-\n",
            "ter configuration was as follows: for LoRA related\n",
            "settings, we used rank of r“8,α“32, and\n",
            "dropout rate of 0.1. For general configuration, we\n",
            "used linear decay for scheduling with initial learn-\n",
            "ing rate of 1e-4 and effective batch size of 4; we\n",
            "trained the model for 5 epochs with weight decay\n",
            "of 0.01 applied. For CORD -specific configuration,\n",
            "we set coefficient for consistency loss strength λas\n",
            "10 and the noise degree for interpolating contexts\n",
            "αas 0.5 throughout our experiments. We leave it\n",
            "as future efforts to search for optimal configuration\n",
            "5huggingface.co/jinaai/jina-colbert-v2\n",
            "6While our work is completely orthogonal to the choice\n",
            "of retriever, we chose this lightweight model that reportedly\n",
            "perform well across several IR benchmarks (Jha et al., 2024).\n",
            "6\n",
            "for these values per different scenarios.\n",
            "C Design of Consistency Loss\n",
            "Using the loss from the first token of the answer\n",
            "only also worked reasonably. We attribute this to\n",
            "that contribution of the consistency loss terms from\n",
            "earlier time steps, i.e., those from the beginning\n",
            "of the ground-truth, are larger than that of those\n",
            "from later time steps. The model output probability\n",
            "distribution for time step tdefined previously in\n",
            "Section 2.1 is indeed conditioned on the shared\n",
            "prefix of the ground-truth answer yăt: as more\n",
            "tokens in the prefix are conditioned in both sides\n",
            "astincreases, the distribution over the token to\n",
            "be immediately followed ftwould converge, as\n",
            "less and less options would be part of a plausible\n",
            "continuation of the answer. This results in terms\n",
            "from later tcontributing smaller to the total loss\n",
            "Lcon, which is why dropping all of them but some at\n",
            "the beginning, just one in the extreme case, suffices\n",
            "to regularize the model output. It is consistent\n",
            "with the findings from previous papers showed that\n",
            "token-level distributional shift between the base\n",
            "and finetuned LLM decreases over time step during\n",
            "decoding (Lin et al., 2024).\n",
            "While the benchmarks we have considered gen-\n",
            "erally require rather short responses, it remains to\n",
            "see if this mechanism of using the first time step\n",
            "only for consistency loss computation also work\n",
            "well for long-form answer generation tasks.\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the PDF to a local file\n",
        "with open(\"rag_doc.pdf\", \"wb\") as f:\n",
        "    f.write(response.content)"
      ],
      "metadata": {
        "id": "g_qM5jx3Oe72"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# laoding the document\n",
        "loader = UnstructuredFileLoader(\"rag_doc.pdf\")"
      ],
      "metadata": {
        "id": "kfqAjKkmJ6a1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n"
      ],
      "metadata": {
        "id": "hIrgL-f7mrHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c510f0b-df1c-4079-a5a1-211088528af1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Initialize the loader with the PDF path\n",
        "loader = PyPDFLoader(\"/content/rag_doc.pdf\")\n",
        "\n",
        "# Load the documents\n",
        "documents = loader.load()\n",
        "\n",
        "# Print the documents\n",
        "print(documents)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypYGwVjon6S",
        "outputId": "5a6f9349-4856-469a-d724-f859fe540d4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': '/content/rag_doc.pdf', 'page': 0}, page_content='CORD: Balancing COnsistency and Rank Distillation\\nfor Robust Retrieval-Augmented Generation\\nYoungwon Lee* Seung-won Hwang* Daniel Campos\\nFilip Grali´nski Zhewei Yao Yuxiong He\\nSnowflake AI Research Seoul National University *\\nAbstract\\nWith the adoption of retrieval-augmented gen-\\neration (RAG), large language models (LLMs)\\nare expected to ground their generation to the\\nretrieved contexts. Yet, this is hindered by posi-\\ntion bias of LLMs, failing to evenly attend to all\\ncontexts. Previous work has addressed this by\\nsynthesizing contexts with perturbed positions\\nof gold segment, creating a position-diversified\\ntrain set. We extend this intuition to propose\\nconsistency regularization with augmentation\\nand distillation. First, we augment each train-\\ning instance with its position perturbation to\\nencourage consistent predictions, regardless of\\nordering. We also distill behaviors of this pair,\\nalthough it can be counterproductive in certain\\nRAG scenarios where the given order from the\\nretriever is crucial for generation quality. We\\nthus propose CORD, balancing COnsistency\\nand Rank Distillation. CORD adaptively sam-\\nples noise-controlled perturbations from an in-\\nterpolation space, ensuring both consistency\\nand respect for the rank prior. Empirical results\\nshow this balance enables CORD to outperform\\nconsistently in diverse RAG benchmarks.\\n1 Introduction\\nRecently, large language models (LLMs) have in-\\ncorporated retrievers to augment input contexts\\nfor more grounded generation. However, during\\nretrieval-augmented generation (RAG), LLMs re-\\nportedly suffer from position bias where they pay\\ndisproportionate attention to different parts, wors-\\nened as the input becomes longer (Liu et al., 2024).\\nAn existing solution has synthesized a training set\\nby randomizing the position of gold segment (An\\net al., 2024). It allows LLMs to implicitly learn\\nthat relevant information can appear at any position,\\nmitigating position bias.\\nOur distinction is to pursue dual goals of (1)\\nCOnsistency for mitigating position bias and (2)\\n*Work done while visiting Snowflake. Correspondence to:\\nseungwonh@snu.ac.kr.\\nFigure 1: Enforcing consistency with (1) augmentation\\n(green) and (2) distillation (blue).\\nMethod (A) (B)\\nGiven order 41.34 56.52\\n+ consistency 36.87 ( Ó) 57.87 ( Ò)\\nCORD (ours) 44.74 (Ò) 58.71 (Ò)\\nTable 1: Representative RAG scenarios A and B, where\\ndistillation may hinder or enhance, respectively.\\nRank Distillation, learning to utilize meaningful\\nsignals in the given order from the retriever and\\nalso to denoise it, for robust RAG.\\nFor CO, we extend the position-perturbing train-\\ning intuition, by augmenting the retriever-given\\norder c with its perturbation c1, sharing the same\\nground truth ˆy. Green arrows in Figure 1 visualize\\nhow this augmentation indirectly enforces consis-\\ntency by guiding predictions y from c and y1from\\nc1, to converge to the ground-truth ˆy.\\nAnother more direct approach is adding a distilla-\\ntion loss penalizing the distributional divergence in\\nall outputs. The blue arrow in Figure 1 visualizes\\nthis loss further incentivizing consistent internal\\nrepresentation, by distilling ‘dark knowledge’ (Hin-\\nton et al., 2015; Sadowski et al., 2015; Furlanello\\net al., 2018) from one to another.\\nHowever, pursuing CO objective alone, without\\nbalancing it with the RD objective, is counterpro-\\nductive in some scenarios as illustrated in Table 1.\\nIt contrasts two representative real-life RAG sce-\\nnarios A and B: 1 In A, retriever provides a reliable\\nrank prior, such that distilling predictions from a\\n1For presentation brevity, we reveal in later section.\\n1\\narXiv:2412.14581v1  [cs.CL]  19 Dec 2024'), Document(metadata={'source': '/content/rag_doc.pdf', 'page': 1}, page_content='Figure 2: (Left) IN2 only uses c1. (Right) We augment\\nthe given order c (top) with perturbed ranking c1 (bot-\\ntom) and use both.\\nrandomized ordering can unlearn this helpful prior,\\nas evidenced by a decrease in generation quality\\nafter consistency regularization. Meanwhile, in B,\\nwhere generation is not sensitive to the given order,\\nCO objective enhances performance.\\nOur technical contribution is to adapt c1 to the\\ngiven scenario, by controlling the degree of pertur-\\nbation, in place of c1 with a fixed randomization.\\nWe define an interpolated space of perturbations\\nand dynamically sample an appropriate level of\\nperturbation from it. Table 1 shows CORD out-\\nperforms in both scenarios, by sampling smaller\\nperturbations in scenario A, where rank prior is\\nimportant, and larger perturbations in scenario B,\\nwhere robustness to position bias is crucial.\\nOur contribution can be summarized as follows:\\n(1) We propose CORD , balancing connsistency\\nand rank distillation in RAG. (2) We show distill-\\ning with a controlled perturbation, sampled from\\nan interpolated space of teachers, is effective across\\n5 diverse RAG scenarios, whereas existing consis-\\ntency methods fall short.\\n2 Method\\n2.1 CO: Consistency regularization\\nWe propose to mitigate position bias by regulariz-\\ning output consistency over possible perturbations,\\nthrough (1) augmentation and (2) distill loss.\\nFirst, we explain how augmenting position-\\nperturbed examples contributes to consistency. We\\nfirst formalize RAG as generating an answer y\\ngiven an input x,\\ny „pp¨|x, cq, (1)\\nalong with the sequence of n retrieved contexts\\nc “ rc1; c2; ¨¨¨ ; cns. Then, for a training triplet\\npx, c, ˆyqthe negative log-likelihood (NLL) loss for\\nmaximum likelihood estimation training is\\nLn “´\\nÿ\\nt\\nlog ppˆyt |x, c, ˆyătq, (2)\\nwhich encourages the model to produce the correct\\nanswer ˆy given the input x and retrieved contexts.\\nInspired by An et al. (2024), referred to as IN2,\\nwe employ position perturbation to augmentc from\\nthe corpus C with c1. For comparison, IN2 synthe-\\nsized question and context pq, cqpairs where the\\ngold passage s for generating the gold answer ˆy\\nappears in various positions. As Figure 2 shows,\\nwe retain both the original pq, c, ˆyqand the per-\\nturbed examples pq, c1, ˆyq: Unlike IN2’s using c1\\nonly for training (orange arrows), we train over the\\naugmented dataset C1which includes both c and c1\\n(blue arrows). Predictions for both are supervised\\nto converge to the same ground-truth ˆy using the\\nloss in Eq 2.\\nSecond, by adding a distill loss, we can further\\nmatch token-level output probability distributions\\nfor c and c1. We use the sum of Jensen-Shannon\\nDivergence (JSD) between output probability dis-\\ntributions at each time step t for this purpose:2\\nLd “\\nÿ\\nt\\nJSD\\n`\\nftpcq}ftpc1q\\n˘\\n, (3)\\nwhere ftpcq “ppˆyt |x, c, ˆyătq. This encourages\\nthe model to align its internal representations of in-\\nput and association with the output, encoded in the\\n‘dark knowledge’ (Hinton et al., 2015; Sadowski\\net al., 2015; Furlanello et al., 2018) across different\\nperturbations.\\nFinally, the two types of loss in Eq 2 and 3 can\\nbe combined to obtain our training objective:\\nL “Ln `λ ¨Ld, (4)\\nwhere the hyperparameter λ determines the relative\\nstrength of the two terms.\\n2.2 RD: Adaptive teacher selection for rank\\ndistillation\\nHowever, as previously outlined in Table 1A, dis-\\ntill loss on a random perturbation c1 may inter-\\nfere with the RD objective in an RAG scenario\\nwhere retriever provides a meaningful ranking c\\nwith valuable prior: In this work, we consider MS\\nMARCO (Bajaj et al., 2018) as a representative ex-\\nample, where an industry-scale complex retrieval\\nsystem provides the ranking.\\nFigure 3A depicts such unlearning of ranker\\nprior, when distilled from a random perturbation\\nin scenario A. The y-axis in the plot represents the\\nprobability the LLM assigns to the ground-truth an-\\nswer, ppˆy |x, cqfor the given order c (solid circle)\\n2While we default to summing all terms, the number of\\ntime steps t to aggregate in Eq 3 can be adjusted for efficiency,\\nas detailed in Appendix C.\\n2'), Document(metadata={'source': '/content/rag_doc.pdf', 'page': 2}, page_content='MS MARCO HotpotQA NQ MN MN-IDK\\nFinetuning Objective R-L GPT-4 EM GPT-4 Acc GPT-4 F1 Acc\\nNo finetuning 41.34 51.94 42.86 66.50 52.18 62.46 56.52 54.82\\nLnll on C1 44.52 57.28 58.62 83.75 55.60 63.51 56.25 95.78\\nCORD 44.74 57.28 63.55 85.72 58.55 63.72 58.71 98.83\\nTable 2: RAG performance with Phi-3 3B as the generator and different finetuning strategies applied.\\nFigure 3: Interpolated sample space for scenario A and\\nB from Table 1, where (A, left) perturbation leads to\\na large drop in probability of ground-truth ˆy, and (B,\\nright) with no such drop.\\nand ppˆy |x, c1qfor random perturbation c1(empty\\ncircle). In MS MARCO, the given order c car-\\nries a useful prior, resulting in high probability of\\nthe ground-truth ppˆy |x, cq. Randomizing this or-\\nder would greatly lower the probability ppˆy |x, c1q,\\nsuch that enforcing consistency between the two\\nwould unlearn the benefit of rank prior.\\nTo tackle this, instead of fixing c1 as a random\\nperturbation, we define a sample space and strategy\\nfor adaptive teacher selection, to control the degree\\nof perturbation for distillation. We introduce an\\ninterpolation of c and c1 with a controlled noise\\ndegree of α, denoted as c1\\nα: Here, the lower ranked\\nα proportion of the retrieved contexts is random-\\nized while the remaining retains the given order. In\\nFigure 3, such interpolated sample is shown as a\\nshaded circle on a dotted line, the interpolated path\\nconnecting c and c1, as the noise degree α varies\\nfrom 0 to 1. For brevity, we assume a desirable sin-\\ngle value of α for the given task is known a priori,\\nand later discuss how to find it in Section 2.3.\\nThis interpolation allows to select a better\\nteacher between c1\\nα and c1 by choosing the one\\nwith a higher probability of predicting the ground\\ntruth. As shown in Figure 3A, small perturbations\\ntend to yield higher y values in scenario A as they\\nretain the given order in part, leading to c1\\nα chosen\\nfor distillation. This corresponds to ensembling\\ntwo retrievers, which agree on top-ranked docu-\\nments but diversify the ranks of the rest.\\nAn added advantage is, the same approach seam-\\nlessly supports scenario B, where there is no con-\\nflict between CO and RD. As illustrated in Fig-\\nure 3B, the y-axis score remains relatively stable\\nacross different orderings, and moreover, the score\\nis no longer sensitive to ordering. Thus, pairing the\\ngiven order with the one that has a higher y score\\nessentially serves the goal of pursuing CO.\\n2.3 Score-aware teacher sampling\\nSo far, we have mainly focused on utilizing rank\\nprior from the retriever; however, the retriever may\\nprovide varying level of information in different\\nRAG scenarios, such as score for each item as well.\\nWe describe how to incorporate such additional\\nsignals into adaptive teacher sampling.\\nWhen no prior knowledge of the distribution of\\nthe probability of ground-truth ppˆy |x, c1\\nαqover the\\ninterpolated path is known, we follow the princi-\\nple of maximum entropy (Jaynes, 1957) to assume\\nuniform distribution. That is, we choose to sample\\nα “ 0.5 from the interpolated space defined in\\nSection 2.2, where α varies in the range of p0, 1q.\\nAlternatively, we utilize retriever scores as a\\nproxy for the unknown distribution of ppˆy |x, c1\\nαq,\\nfrom which the optimal noise level α can be de-\\ntermined. Specifically, we aim to extract the most\\nconfident top-ranked contexts identified by the re-\\ntriever, by preserving the contexts ranked above\\nthe largest discontinuity in scores and perturbing\\nthe rest. Given scores si for each retrieved context\\nci P c, which are sorted in descending order of\\nscore, i.e., s1 ą s2 ą ¨¨¨ ąsn, we locate the\\nadjacent pair of passages with the largest gap in\\nretriever score ˆi “argmax ipsi ´si`1qand per-\\nturb the passages ranked lower than ˆi. In other\\nwords, we choose α “1 ´ˆi{n for this example.\\nIntuitively, this approximates finding the largest\\nacceptable degree of noise that would still result in\\nsufficiently high ppˆy |x, c1\\nαq.\\n3 Results\\nWe design evaluations to answer these research\\nquestions: (RQ1) Does CORD pursue dual goals\\n3'), Document(metadata={'source': '/content/rag_doc.pdf', 'page': 3}, page_content='MS MARCO\\nFinetuning Method R-L GPT-4\\nNo finetuning 41.34 51.94\\nLnll on C 41.81 51.94\\nLnll on C1 44.52 57.28\\nCORD 44.74 57.28\\nTable 3: Without augmentation (second row) there is a\\nclear performance gap compared to models trained with\\nconsistency objectives (third and fourth row).\\nMN MN-IDK\\nFinetuning Method F1 Acc\\nCORD 58.71 98.83\\n+ Adaptive α 59.16 98.83\\nTable 4: Effect of dynamically adjusting α based on\\nretriever score.\\nof CO and RD effectively? (RQ2) Does CORD\\nadaptively choose pc, c1qpair in different scenar-\\nios? (RQ3) How can the noise degree α for inter-\\npolation be tuned per task or example?\\n3.1 Experimental settings\\nWe have evaluated our proposed method on several\\nQA benchmarks: MS MARCO (Bajaj et al., 2018),\\nHotpotQA (Yang et al., 2018), NaturalQuestions\\n(Kwiatkowski et al. (2019); NQ) as reorganized by\\nLiu et al. (2024). We further consider multi-needle\\n(MN) dataset, which is built following An et al.\\n(2024), as a scenario where irrelevant contexts are\\nprevalent and retriever prior is not meaningful.3\\nFor evaluation, we used widely reported metrics\\nfor each benchmark, namely ROUGE-L for MS\\nMARCO, exact match (EM) for HotpotQA, and\\nspan-based exact match, or ‘accuracy’ for NQ. We\\nalso adopted the evaluation protocol from Yang\\net al. (2024) using GPT-4, allowing more flexibil-\\nity in answers. For MN where answers typically\\ncontain a few sentences, we report sentence-level\\nF1, and for MN-IDK, an unanswerable split of MN,\\nwe report accuracy. Further details can be found in\\nAppendix B.\\n3.2 Results\\nBias mitigation and rank distillationTable 2\\nshows that our proposed method outperforms the\\nbaselines across all benchmarks, validating its ef-\\nfectiveness in pursuing dual goals of CO and RD.\\nIn addition, Table 3 shows the importance of\\n3This corresponds to scenario B in Table 1 and Figure 3.\\nFigure 4: (Top) On MS MARCO, the interpolated noise-\\ncontrolled perturbation c1\\nα (dark blue) is much more\\nlikely to be paired with the given order c, than c1 (light\\nblue). (Bottom) The gap is much smaller on MN.\\ndenoising through consistency in rank distillation.\\nThere is a clear performance gap between the\\nmodel trained on the given order c without aug-\\nmentation (2nd row), and those augmented (3rd &\\n4th) on MS MARCO. This suggests that even with\\na strong rank prior, consistency across slight pertur-\\nbation positively contributes to RD, by mitigating\\npotential bias from retriever or generator.\\nAdaptive pair selection CORD indeed selects\\nthe proper teacher for enforcing consistency, while\\nthe tendency in choices exhibit clear difference\\nper different RAG scenario, as shown in Figure 4.\\nThe ratio of c1\\nα paired with c is shown with dark\\nblue, while the ratio of c1paired with c is presented\\nby light blue bar. Comparing MS MARCO (top)\\nand MN (bottom), it is clearly shown that c1\\nα is\\nmuch more likely to be paired with c in the former,\\nwhere the RD objective is more prominent. This\\nsupports our rationale behind designing adaptive\\nteacher selection in Section 2.2.\\nScore-aware teacher sampling Table 4 shows\\nthat score-aware dynamic adjustment of α, de-\\nscribed in Section 2.3 brings further gain; the effec-\\ntive mean value of α throughout the train set was\\n0.8, suggesting a larger portion of the ranking was\\nallowed to be perturbed.\\n4 Conclusion\\nWe have presented CORD , to balance the tension\\nbetween CO (consistency) and RD (rank distilla-\\ntion) objectives in RAG. For the former, we aug-\\nment order-perturbed contexts and add distillation\\nloss for explicit consistency regularization. For\\nthe latter, CORD adaptively chooses desirable de-\\ngree of perturbation to prevent unlearning valuable\\nprior from the retriever.CORD consistently outper-\\nforms existing methods in diverse RAG scenarios.\\n4'), Document(metadata={'source': '/content/rag_doc.pdf', 'page': 4}, page_content='Limitations\\nWhether our findings generalize over diverse mod-\\nels can be further explored. In addition, the pros\\nand cons of diverse mixing strategies for an inter-\\npolated sample space, such as employing another\\nretriever for mix, can be explored; we leave it as\\nfuture work.\\nReferences\\nShengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng,\\nand Jian-Guang Lou. 2024. Make your llm fully\\nutilize the context. Preprint, arXiv:2404.16811.\\nPayal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\\nJianfeng Gao, Xiaodong Liu, Rangan Majumder,\\nAndrew McNamara, Bhaskar Mitra, Tri Nguyen,\\nMir Rosenberg, Xia Song, Alina Stoica, Saurabh\\nTiwary, and Tong Wang. 2018. Ms marco: A human\\ngenerated machine reading comprehension dataset.\\nPreprint, arXiv:1611.09268.\\nChing-Yao Chuang and Youssef Mroueh. 2021. Fair\\nmixup: Fairness via interpolation. In 9th Inter-\\nnational Conference on Learning Representations,\\nICLR 2021, Virtual Event, Austria, May 3-7, 2021 .\\nOpenReview.net.\\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\\nData engineering for scaling language models to 128k\\ncontext. In Forty-first International Conference on\\nMachine Learning, ICML 2024, Vienna, Austria, July\\n21-27, 2024. OpenReview.net.\\nTommaso Furlanello, Zachary Lipton, Michael Tschan-\\nnen, Laurent Itti, and Anima Anandkumar. 2018.\\nBorn again neural networks. In Proceedings of the\\n35th International Conference on Machine Learn-\\ning, volume 80 of Proceedings of Machine Learning\\nResearch, pages 1607–1616. PMLR.\\nGeoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2015.\\nDistilling the knowledge in a neural network. In\\nNIPS Deep Learning and Representation Learning\\nWorkshop.\\nE. T. Jaynes. 1957. Information theory and statistical\\nmechanics. Phys. Rev., 106:620–630.\\nRohan Jha, Bo Wang, Michael Günther, Saba Sturua,\\nMohammad Kalim Akram, and Han Xiao. 2024.\\nJina-colbert-v2: A general-purpose multilingual late\\ninteraction retriever. CoRR, abs/2408.16672.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\\nton Lee, Kristina Toutanova, Llion Jones, Matthew\\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\\nral questions: A benchmark for question answering\\nresearch. Transactions of the Association for Compu-\\ntational Linguistics, 7:452–466.\\nBill Yuchen Lin, Abhilasha Ravichander, Ximing Lu,\\nNouha Dziri, Melanie Sclar, Khyathi Chandu, Chan-\\ndra Bhagavatula, and Yejin Choi. 2024. The unlock-\\ning spell on base llms: Rethinking alignment via\\nin-context learning. In International Conference on\\nLearning Representations.\\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\\njape, Michele Bevilacqua, Fabio Petroni, and Percy\\nLiang. 2024. Lost in the middle: How language mod-\\nels use long contexts. Transactions of the Association\\nfor Computational Linguistics, 12:157–173.\\nPeter Sadowski, Julian Collado, Daniel Whiteson, and\\nPierre Baldi. 2015. Deep learning, dark knowl-\\nedge, and dark matter. In Proceedings of the NIPS\\n2014 Workshop on High-energy Physics and Ma-\\nchine Learning, volume 42 of Proceedings of Ma-\\nchine Learning Research , pages 81–87, Montreal,\\nCanada. PMLR.\\nQizhe Xie, Zihang Dai, Eduard H. Hovy, Thang Luong,\\nand Quoc Le. 2020. Unsupervised data augmenta-\\ntion for consistency training. In Advances in Neural\\nInformation Processing Systems 33: Annual Confer-\\nence on Neural Information Processing Systems 2020,\\nNeurIPS 2020, December 6-12, 2020, virtual.\\nXiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla,\\nXiangsen Chen, Sajal Choudhary, Rongze Daniel\\nGui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong,\\nBrian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan,\\nChenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang,\\nLei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah,\\nRakesh Wanga, Anuj Kumar, Wen-tau Yih, and\\nXin Luna Dong. 2024. CRAG - comprehensive RAG\\nbenchmark. CoRR, abs/2406.04744.\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\\npher D. Manning. 2018. HotpotQA: A dataset for\\ndiverse, explainable multi-hop question answering.\\nIn Proceedings of the 2018 Conference on Empiri-\\ncal Methods in Natural Language Processing, pages\\n2369–2380, Brussels, Belgium. Association for Com-\\nputational Linguistics.\\n5'), Document(metadata={'source': '/content/rag_doc.pdf', 'page': 5}, page_content='A Related Work\\nA.1 Position bias in long context LLM\\nLiu et al. (2024) and similar works have shown that\\nLLMs favor input contexts placed at the beginning\\nor end of the input, a tendency that benchmarks\\nlike needle-in-a-haystack4 aim to assess by testing\\ntheir ability to locate relevant information (‘nee-\\ndle’) within long, potentially irrelevant contexts\\n(‘haystack’). An et al. (2024) extended this un-\\nderstanding by training models on synthetic data,\\nintentionally perturbing a position of gold segment\\nand adding random noises. Similarly, Fu et al.\\n(2024) examined continual pretraining of LLMs\\non long-context data to expand their context win-\\ndow size for retrieving information.\\nOur distinction is to use position perturbation\\nfor a different objective of data augmentation for\\nconsistency training.\\nA.2 Data augmentation for consistency\\nPairing a datapoint with a counterfactual applying\\na small perturbation has been mainly studied for\\nrobust training on simpler tasks such as classifica-\\ntion (Xie et al., 2020). To our knowledge, we are\\nthe first to augment a position-perturbed retriever\\nduring training and enforce consistency for RAG.\\nAnother related line of work is interpolating\\ntwo training instances (Chuang and Mroueh, 2021),\\nwhich we extend to define a space of controlled per-\\nturbations for dynamic adaptation in Section 2.2.\\nB Implementation Details\\nMN construction For MN data construction, we\\ngenerally followed the recipe from An et al. (2024),\\nwith the subtle difference that Mixtral was used for\\nquestion and answer generation. When preparing\\nthe MN dataset following An et al. (2024), we gen-\\nerally abide by their practices, while using Mixtral\\nas the LLM for question and answer extraction, and\\nemployed GPT-4 to verify it. For the seed corpus,\\nwe utilized the same realnewslike subset from\\nthe C4 corpus as C. We refer the reader to their\\noriginal paper for more details.\\nIn addition, to study how LLMs can be trained\\nto refuse to answer when there are insufficient evi-\\ndence provided, rather than to hallucinate, we split\\nthe test set into two settings, answerable and unan-\\nswerable: In the latter, dubbed MN-IDK, the gold\\nsegment s that provides the evidence to answer the\\n4github.com/gkamradt/LLMTest_NeedleInAHaystack\\ngiven question is omitted. Thus, the model is ex-\\npected to answer it does not have enough evidence\\nin the contexts to provide the correct answer, or, ‘I\\ndon’t know.’\\nMetrics The evaluation protocol involving GPT-\\n4 as the judge from Yang et al. (2024) evaluates\\nthe correctness of the answer with greater flexibil-\\nity, compared to the canonical lexical match based\\nmetrics, and is known to align better with human\\njudgment. Also, it penalizes hallucinated response\\nmore than simply abstaining.\\nWhile other benchmarks considered in this work\\nrequire shorter answers, expected answers in MN\\nand MN-IDK typically comprise of a few sentences:\\nthus, we report sentence-level F1 score for MN,\\nwhere GPT-4 was used as a judge in the same man-\\nner as the method described above to decide each\\nsentence in the generated answer is supported by\\nthe ground-truth (precision), and vice versa (re-\\ncall). For MN-IDK, GPT-4 determined whether the\\nmodel response successfully refused to provide the\\nanswer or not, and we reported the accuracy.\\nTraining For MS MARCO, HotpotQA and MN,\\nwe finetuned Phi-3 3B model on their respective\\ntrain data: for MS MARCO, we used 20k examples\\nheld out from v2.1 dev set for training, and used\\nnon-overlapping subset for testing.\\nFor training with CORD on MN, as described in\\nSection 2.2, we generated an artificial ranking over\\nthe passages by reranking them with a ColBERT\\nvariant model from Jina AI,56 which also provided\\nscores for each passage. This artificial ranking\\nserves as the opposite extreme of the interpolated\\nperturbation space, c1.\\nThe base model, Phi-3 3B, was trained with\\nLoRA at bf16 precision. The relevant hyperparame-\\nter configuration was as follows: for LoRA related\\nsettings, we used rank of r “ 8, α “ 32, and\\ndropout rate of 0.1. For general configuration, we\\nused linear decay for scheduling with initial learn-\\ning rate of 1e-4 and effective batch size of 4; we\\ntrained the model for 5 epochs with weight decay\\nof 0.01 applied. For CORD -specific configuration,\\nwe set coefficient for consistency loss strength λ as\\n10 and the noise degree for interpolating contexts\\nα as 0.5 throughout our experiments. We leave it\\nas future efforts to search for optimal configuration\\n5huggingface.co/jinaai/jina-colbert-v2\\n6While our work is completely orthogonal to the choice\\nof retriever, we chose this lightweight model that reportedly\\nperform well across several IR benchmarks (Jha et al., 2024).\\n6'), Document(metadata={'source': '/content/rag_doc.pdf', 'page': 6}, page_content='for these values per different scenarios.\\nC Design of Consistency Loss\\nUsing the loss from the first token of the answer\\nonly also worked reasonably. We attribute this to\\nthat contribution of the consistency loss terms from\\nearlier time steps, i.e., those from the beginning\\nof the ground-truth, are larger than that of those\\nfrom later time steps. The model output probability\\ndistribution for time step t defined previously in\\nSection 2.1 is indeed conditioned on the shared\\nprefix of the ground-truth answer yăt: as more\\ntokens in the prefix are conditioned in both sides\\nas t increases, the distribution over the token to\\nbe immediately followed ft would converge, as\\nless and less options would be part of a plausible\\ncontinuation of the answer. This results in terms\\nfrom later t contributing smaller to the total loss\\nLcon, which is why dropping all of them but some at\\nthe beginning, just one in the extreme case, suffices\\nto regularize the model output. It is consistent\\nwith the findings from previous papers showed that\\ntoken-level distributional shift between the base\\nand finetuned LLM decreases over time step during\\ndecoding (Lin et al., 2024).\\nWhile the benchmarks we have considered gen-\\nerally require rather short responses, it remains to\\nsee if this mechanism of using the first time step\\nonly for consistency loss computation also work\\nwell for long-form answer generation tasks.\\n7')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=2000,  # Maximum number of characters per chunk\n",
        "    chunk_overlap=400  # Number of characters that overlap between consecutive chunks\n",
        ")\n"
      ],
      "metadata": {
        "id": "HW_traVsJ6kj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "11kK5SjtJ6nH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(texts)"
      ],
      "metadata": {
        "id": "OmpdiqK0J6pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb544a3f-b60f-4a02-b67a-dd2d01b45276"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "8M_0cvDwPPtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1371b89-0110-41dd-d368-5f28c4b2671d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[4]"
      ],
      "metadata": {
        "id": "5mhakbo9cSSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1b3a3b-24b6-404d-dcc1-e53083314f32"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/rag_doc.pdf', 'page': 4}, page_content='Limitations\\nWhether our findings generalize over diverse mod-\\nels can be further explored. In addition, the pros\\nand cons of diverse mixing strategies for an inter-\\npolated sample space, such as employing another\\nretriever for mix, can be explored; we leave it as\\nfuture work.\\nReferences\\nShengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng,\\nand Jian-Guang Lou. 2024. Make your llm fully\\nutilize the context. Preprint, arXiv:2404.16811.\\nPayal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\\nJianfeng Gao, Xiaodong Liu, Rangan Majumder,\\nAndrew McNamara, Bhaskar Mitra, Tri Nguyen,\\nMir Rosenberg, Xia Song, Alina Stoica, Saurabh\\nTiwary, and Tong Wang. 2018. Ms marco: A human\\ngenerated machine reading comprehension dataset.\\nPreprint, arXiv:1611.09268.\\nChing-Yao Chuang and Youssef Mroueh. 2021. Fair\\nmixup: Fairness via interpolation. In 9th Inter-\\nnational Conference on Learning Representations,\\nICLR 2021, Virtual Event, Austria, May 3-7, 2021 .\\nOpenReview.net.\\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\\nData engineering for scaling language models to 128k\\ncontext. In Forty-first International Conference on\\nMachine Learning, ICML 2024, Vienna, Austria, July\\n21-27, 2024. OpenReview.net.\\nTommaso Furlanello, Zachary Lipton, Michael Tschan-\\nnen, Laurent Itti, and Anima Anandkumar. 2018.\\nBorn again neural networks. In Proceedings of the\\n35th International Conference on Machine Learn-\\ning, volume 80 of Proceedings of Machine Learning\\nResearch, pages 1607–1616. PMLR.\\nGeoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2015.\\nDistilling the knowledge in a neural network. In\\nNIPS Deep Learning and Representation Learning\\nWorkshop.\\nE. T. Jaynes. 1957. Information theory and statistical\\nmechanics. Phys. Rev., 106:620–630.\\nRohan Jha, Bo Wang, Michael Günther, Saba Sturua,\\nMohammad Kalim Akram, and Han Xiao. 2024.\\nJina-colbert-v2: A general-purpose multilingual late\\ninteraction retriever. CoRR, abs/2408.16672.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\\nton Lee, Kristina Toutanova, Llion Jones, Matthew\\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\\nral questions: A benchmark for question answering\\nresearch. Transactions of the Association for Compu-\\ntational Linguistics, 7:452–466.\\nBill Yuchen Lin, Abhilasha Ravichander, Ximing Lu,\\nNouha Dziri, Melanie Sclar, Khyathi Chandu, Chan-\\ndra Bhagavatula, and Yejin Choi. 2024. The unlock-\\ning spell on base llms: Rethinking alignment via\\nin-context learning. In International Conference on\\nLearning Representations.\\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\\njape, Michele Bevilacqua, Fabio Petroni, and Percy\\nLiang. 2024. Lost in the middle: How language mod-\\nels use long contexts. Transactions of the Association\\nfor Computational Linguistics, 12:157–173.\\nPeter Sadowski, Julian Collado, Daniel Whiteson, and\\nPierre Baldi. 2015. Deep learning, dark knowl-\\nedge, and dark matter. In Proceedings of the NIPS\\n2014 Workshop on High-energy Physics and Ma-\\nchine Learning, volume 42 of Proceedings of Ma-\\nchine Learning Research , pages 81–87, Montreal,\\nCanada. PMLR.\\nQizhe Xie, Zihang Dai, Eduard H. Hovy, Thang Luong,\\nand Quoc Le. 2020. Unsupervised data augmenta-\\ntion for consistency training. In Advances in Neural\\nInformation Processing Systems 33: Annual Confer-\\nence on Neural Information Processing Systems 2020,\\nNeurIPS 2020, December 6-12, 2020, virtual.\\nXiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla,\\nXiangsen Chen, Sajal Choudhary, Rongze Daniel\\nGui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong,\\nBrian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan,\\nChenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang,\\nLei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah,\\nRakesh Wanga, Anuj Kumar, Wen-tau Yih, and\\nXin Luna Dong. 2024. CRAG - comprehensive RAG\\nbenchmark. CoRR, abs/2406.04744.\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\\npher D. Manning. 2018. HotpotQA: A dataset for\\ndiverse, explainable multi-hop question answering.\\nIn Proceedings of the 2018 Conference on Empiri-\\ncal Methods in Natural Language Processing, pages\\n2369–2380, Brussels, Belgium. Association for Com-\\nputational Linguistics.\\n5')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize the HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()\n"
      ],
      "metadata": {
        "id": "WCtqKTYRPZa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "054b19e878f34d08a60c404afeba7e5d",
            "c43967d6a42c46c6931e9e9f202ceca9",
            "2aa37cff55f9481090a36c66cd86b6b1",
            "4490c34a4edc429980f995718bc057dd",
            "3cd837aeb63144fe9aa9dd64b7376f93",
            "10fb1ab628dd4747867a5656aa2a743d",
            "408231f820f146a2ae298f7604111bef",
            "e58fc6d028264601acf6290e413cee98",
            "0e6adc5513ce4677a870d4d19e22eb21",
            "0ff75ae816e54569911437cf8c8b5834",
            "ab051f52250d4705b22f0cdd7685209c",
            "0b13e0d4a86042489b46efbd0e3be2bd",
            "1c0a3688bf3d441abd58a0e99ca87cee",
            "cd9d7225386140579e3f0292be3df4b6",
            "1ba0cdff0a434502a038a646da489e0f",
            "492540531def4ea28bb5986411ce2c03",
            "fb549c60448645d7b31ffa8110a315ba",
            "74baeabc938c4e04931b845d489a29bc",
            "9d376c01b7744902acf98ae3e0770d9f",
            "15c13e8dc56c408697428d418d269324",
            "278f92b8d8174d0e8677842765b371f9",
            "9f5b988caeb54074bd125390c8bad701",
            "9df9fcdacd5d4fe2b7f9b55ebce9cd63",
            "36092e4d6bfc48c8b2e58feaeec98689",
            "8e9bc5f9cb61465abf3fa3a82a21912e",
            "74f01b0454864e91ad0a17e433dd3796",
            "9bf75a3d9c9448c3a99393547842ced9",
            "dcfb6014a7784f979ff39650f844f39a",
            "5507c96fabc54def802dee1b309ad99d",
            "c733e52103324671a33900a6f560bb54",
            "a825f9a445cc42cb99cc19421baa6b73",
            "bd70c19e1fd744919640a8a174b27533",
            "43f18cd7ab76432abcdf72ceb790ce6a",
            "767f76ec303245d38b6f7aaad09d07b7",
            "23b7920ad3664494bb818fc9204d9b98",
            "4399fa3a3ae24e7f9116bb20c2d7139e",
            "9b4c59d07f8f4d7592097b4aed055e74",
            "39d4cdfc52584c348a2a145e51fcc810",
            "025211a100e942d68e3dd637a30e1132",
            "fda1d5d951044902bcd5816a69413bee",
            "5eb1e51675a545359aff9b446ee4962c",
            "3221e2bc7cb54485bcab3790be501a0d",
            "cf89b8cdc3cf43749682f2b6f4315c1e",
            "a6a033564fb24265a56c92d319d56454",
            "e49bc690841242a090597643834cbd69",
            "2a01b9a8a10d48709b3850b40c4fb00c",
            "76da0a010cbf43d98c2f2850b37bee2f",
            "90d6c6a7184d488a9bfb72208e150a20",
            "b10f8feae4104444bc9d3dc21032a4f6",
            "e435fe7e3be648d7bb42255f63b16b8f",
            "fd60f84b07d6439cac9cfe91bf1b91f7",
            "9a7dcd5310cf4c639eb948a18a69db33",
            "afb061d43e5844a48b063fbbf48675f6",
            "1fa4cc4067e34009a6620a0ff4b17390",
            "48caa172e13949258a2fc68083c26618",
            "0a13c8d23004417ca73dff3c9b0e93c1",
            "b3bdeddc09b74f14a0053283abc4c285",
            "33d7df246667415e898ebcb279f8e04c",
            "f7c821044fde44859fc30e91017c149c",
            "fb5a94265ee64a518bdab4cf3d392757",
            "393450d260544e73a1cc39ee73608776",
            "af70f049d30d4a569191c7816fe2aed8",
            "002b81f739f94801bc7d271ea9fc2052",
            "300c76c1a79b4221880a208d14336c94",
            "3842a449febc45cf9fbf8cc7034ee2f8",
            "2ecc5968d85a49b0ace2d78268ad9769",
            "fefb3351baa440f2b33eca55b7250af7",
            "bca667cb27684f8ea763c7c90bfd802a",
            "b42493bd2b364e10818192fdbd478d04",
            "cddec9faecaa4414a4370c1962cd9d71",
            "4b6f22c97643411996d6c5eab51baef7",
            "1618c202988643d1b82c624540390a98",
            "20b56c292a9144218a84d8da1c2caba0",
            "11cd018eb6404092b4c798353ba248f2",
            "10fd72883e224b16b9b44acd42cb9988",
            "3059179fb6f24e5885fa71f1335fdeca",
            "e83e9bd3e98d47ecb6895a52f58467b8",
            "233e89b1cc2e4bf897c38588988d8f50",
            "a83aa67eed2f495eb226a422ec5fd350",
            "561cd6a61d8b475ab49f9eb8636fdbf7",
            "997c2c8206db49b4aadd625df9c9cdca",
            "c925cf6c6d9440b7872ee72f1d02ff97",
            "7375b383a317403e8ad1f7347c81b8e7",
            "00fe5d4b166344308c1ced9d67928989",
            "3cb5352d7cfd48efae5dd566c06091e4",
            "a4f5d48b7f424e0b9fda0662acd774b6",
            "3ddf6ca834ed4571b3e5c06b4bc42403",
            "2fb4aa47ce994af7a00ef0e141185eae",
            "d78cb730306040ad94eaa2e4ec330802",
            "9e6130c98feb4d1eae43a9f25456518f",
            "485bb940051c4cb09074a804e152bd98",
            "3f2a9bbf948049ebb6389dfb7c1f440a",
            "7c940ff4011b420e8c260430544a6319",
            "8a8443d1835b4b23ba1a83c166d6ae45",
            "54b3faa040d2403699a6b5d91175bb4e",
            "7f0c0a1994aa469698263fae9a3d9025",
            "eb9f53f4d20046f99c737603c598c13e",
            "f0d44e64ce504266b9e0d353afcb174d",
            "ade70fd2b729450198adaf6c200ad7a2",
            "47b5b7f8d19f43f48d27311dc46a9b02",
            "b983ba645bf549048e0a531822932302",
            "9eca31836e414e2dbf7c7d8fe0803d0c",
            "1ff263affde3482395008600f7fdc458",
            "9b2e087124f64883ad02f823b1daf5f4",
            "e1c670ba8d8e480f91b4e945c7541aec",
            "20d9b94c9dd5403d898a1bde5148460a",
            "3595ef4c65bc46ea9e1e274f13e0f5ce",
            "f9e24886b9ee4704841a6a7b48be64d4",
            "fce93db606ff484a82af219b1f644013",
            "d3d1ad41ffea40f2bacea013ce3a7da3",
            "a8990c8c02ed4e7eb4329d556589ca58",
            "0ef590bd5c144cd0aa79a35e7ff2eda7",
            "d54accf7e1774e3dbc23d569c3b02f4e",
            "32015f22756e48a883414eeac9c01140",
            "deea1d70782b4eba97ffa5a36c459cd5",
            "3afdcc89424541db926991f0886a3f72",
            "d4f81806f5bb4d2f883c843cb39de543",
            "55a3982b8bc14c6982c10fdc9adb5245",
            "0e497d4a16eb4a7eb11280b82bd8afcc",
            "8a6633869ee043eeb75b6d55ee773d46",
            "2dcd76439cbd4cad90ad6d0a9e66caa4"
          ]
        },
        "outputId": "15a67b05-8fbd-4220-ba0a-6b44e6bd25e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-aa5cbeb4d92e>:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "054b19e878f34d08a60c404afeba7e5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b13e0d4a86042489b46efbd0e3be2bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df9fcdacd5d4fe2b7f9b55ebce9cd63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "767f76ec303245d38b6f7aaad09d07b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e49bc690841242a090597643834cbd69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a13c8d23004417ca73dff3c9b0e93c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fefb3351baa440f2b33eca55b7250af7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "233e89b1cc2e4bf897c38588988d8f50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d78cb730306040ad94eaa2e4ec330802"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47b5b7f8d19f43f48d27311dc46a9b02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8990c8c02ed4e7eb4329d556589ca58"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the document embeddings in a vector database (Chroma)\n",
        "persist_directory = \"vector_db\"\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "WzDMUEe7PZdl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve information from the vector store (useful for QA tasks)\n",
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "SXZnwNruPZk9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize the LLM (language model) from Groq API with the specified model and temperature\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-70b-versatile\",  # Specify the model version\n",
        "    temperature=0  # Set the temperature (0 for deterministic, higher for more randomness)\n",
        ")"
      ],
      "metadata": {
        "id": "6tNGgbgHPZng"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "ex6roK9qPwKo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke the qa chain and get a response for user query\n",
        "# Example of using the LLM to generate a response for a query\n",
        "query = \"What is RAG in pdf \"\n",
        "response = qa_chain.invoke({\"query\": query})"
      ],
      "metadata": {
        "id": "M9BC0EAXPwNH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "IfTnEQL0PwPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a312a0-5525-40a6-d6cb-36f009fa3de1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'What is RAG in pdf ', 'result': 'RAG stands for Retrieval-Augmented Generation. It is a type of natural language processing (NLP) model that combines the strengths of retrieval-based and generation-based approaches to answer questions or generate text.\\n\\nIn a RAG model, the input is first passed through a retriever, which retrieves a set of relevant contexts or passages from a large corpus of text. The retriever is typically a neural network-based model that is trained to rank the passages based on their relevance to the input.\\n\\nThe retrieved passages are then passed through a generator, which is another neural network-based model that generates the final output text based on the input and the retrieved passages. The generator can be a language model, a machine translation model, or any other type of text generation model.\\n\\nThe key idea behind RAG is to leverage the strengths of both retrieval-based and generation-based approaches. Retrieval-based approaches are good at finding relevant information, but they can struggle to generate coherent and fluent text. Generation-based approaches, on the other hand, can generate coherent and fluent text, but they can struggle to find relevant information.\\n\\nBy combining the two approaches, RAG models can generate high-quality text that is both relevant and coherent. RAG has been applied to a variety of NLP tasks, including question answering, text summarization, and dialogue generation.\\n\\nIn the context of the provided PDF, RAG is used to evaluate the performance of the proposed CORD (Consistency and Rank Distillation) method, which is a training objective for RAG models that aims to improve their performance by regularizing the output consistency over possible perturbations.', 'source_documents': [Document(metadata={'page': 2, 'source': '/content/rag_doc.pdf'}, page_content='MS MARCO HotpotQA NQ MN MN-IDK\\nFinetuning Objective R-L GPT-4 EM GPT-4 Acc GPT-4 F1 Acc\\nNo finetuning 41.34 51.94 42.86 66.50 52.18 62.46 56.52 54.82\\nLnll on C1 44.52 57.28 58.62 83.75 55.60 63.51 56.25 95.78\\nCORD 44.74 57.28 63.55 85.72 58.55 63.72 58.71 98.83\\nTable 2: RAG performance with Phi-3 3B as the generator and different finetuning strategies applied.\\nFigure 3: Interpolated sample space for scenario A and\\nB from Table 1, where (A, left) perturbation leads to\\na large drop in probability of ground-truth ˆy, and (B,\\nright) with no such drop.\\nand ppˆy |x, c1qfor random perturbation c1(empty\\ncircle). In MS MARCO, the given order c car-\\nries a useful prior, resulting in high probability of\\nthe ground-truth ppˆy |x, cq. Randomizing this or-\\nder would greatly lower the probability ppˆy |x, c1q,\\nsuch that enforcing consistency between the two\\nwould unlearn the benefit of rank prior.\\nTo tackle this, instead of fixing c1 as a random\\nperturbation, we define a sample space and strategy\\nfor adaptive teacher selection, to control the degree\\nof perturbation for distillation. We introduce an\\ninterpolation of c and c1 with a controlled noise\\ndegree of α, denoted as c1\\nα: Here, the lower ranked\\nα proportion of the retrieved contexts is random-\\nized while the remaining retains the given order. In\\nFigure 3, such interpolated sample is shown as a\\nshaded circle on a dotted line, the interpolated path\\nconnecting c and c1, as the noise degree α varies\\nfrom 0 to 1. For brevity, we assume a desirable sin-\\ngle value of α for the given task is known a priori,\\nand later discuss how to find it in Section 2.3.\\nThis interpolation allows to select a better\\nteacher between c1\\nα and c1 by choosing the one\\nwith a higher probability of predicting the ground\\ntruth. As shown in Figure 3A, small perturbations\\ntend to yield higher y values in scenario A as they\\nretain the given order in part, leading to c1\\nα chosen\\nfor distillation. This corresponds to ensembling\\ntwo retrievers, which agree on top-ranked docu-\\nments but diversify the ranks of the rest.\\nAn added advantage is, the same approach seam-\\nlessly supports scenario B, where there is no con-\\nflict between CO and RD. As illustrated in Fig-\\nure 3B, the y-axis score remains relatively stable\\nacross different orderings, and moreover, the score\\nis no longer sensitive to ordering. Thus, pairing the\\ngiven order with the one that has a higher y score\\nessentially serves the goal of pursuing CO.\\n2.3 Score-aware teacher sampling\\nSo far, we have mainly focused on utilizing rank\\nprior from the retriever; however, the retriever may\\nprovide varying level of information in different\\nRAG scenarios, such as score for each item as well.\\nWe describe how to incorporate such additional\\nsignals into adaptive teacher sampling.\\nWhen no prior knowledge of the distribution of\\nthe probability of ground-truth ppˆy |x, c1\\nαqover the\\ninterpolated path is known, we follow the princi-\\nple of maximum entropy (Jaynes, 1957) to assume\\nuniform distribution. That is, we choose to sample\\nα “ 0.5 from the interpolated space defined in\\nSection 2.2, where α varies in the range of p0, 1q.\\nAlternatively, we utilize retriever scores as a\\nproxy for the unknown distribution of ppˆy |x, c1\\nαq,\\nfrom which the optimal noise level α can be de-\\ntermined. Specifically, we aim to extract the most\\nconfident top-ranked contexts identified by the re-\\ntriever, by preserving the contexts ranked above\\nthe largest discontinuity in scores and perturbing\\nthe rest. Given scores si for each retrieved context\\nci P c, which are sorted in descending order of\\nscore, i.e., s1 ą s2 ą ¨¨¨ ąsn, we locate the\\nadjacent pair of passages with the largest gap in\\nretriever score ˆi “argmax ipsi ´si`1qand per-\\nturb the passages ranked lower than ˆi. In other\\nwords, we choose α “1 ´ˆi{n for this example.\\nIntuitively, this approximates finding the largest\\nacceptable degree of noise that would still result in\\nsufficiently high ppˆy |x, c1\\nαq.\\n3 Results\\nWe design evaluations to answer these research\\nquestions: (RQ1) Does CORD pursue dual goals\\n3'), Document(metadata={'page': 1, 'source': '/content/rag_doc.pdf'}, page_content='Figure 2: (Left) IN2 only uses c1. (Right) We augment\\nthe given order c (top) with perturbed ranking c1 (bot-\\ntom) and use both.\\nrandomized ordering can unlearn this helpful prior,\\nas evidenced by a decrease in generation quality\\nafter consistency regularization. Meanwhile, in B,\\nwhere generation is not sensitive to the given order,\\nCO objective enhances performance.\\nOur technical contribution is to adapt c1 to the\\ngiven scenario, by controlling the degree of pertur-\\nbation, in place of c1 with a fixed randomization.\\nWe define an interpolated space of perturbations\\nand dynamically sample an appropriate level of\\nperturbation from it. Table 1 shows CORD out-\\nperforms in both scenarios, by sampling smaller\\nperturbations in scenario A, where rank prior is\\nimportant, and larger perturbations in scenario B,\\nwhere robustness to position bias is crucial.\\nOur contribution can be summarized as follows:\\n(1) We propose CORD , balancing connsistency\\nand rank distillation in RAG. (2) We show distill-\\ning with a controlled perturbation, sampled from\\nan interpolated space of teachers, is effective across\\n5 diverse RAG scenarios, whereas existing consis-\\ntency methods fall short.\\n2 Method\\n2.1 CO: Consistency regularization\\nWe propose to mitigate position bias by regulariz-\\ning output consistency over possible perturbations,\\nthrough (1) augmentation and (2) distill loss.\\nFirst, we explain how augmenting position-\\nperturbed examples contributes to consistency. We\\nfirst formalize RAG as generating an answer y\\ngiven an input x,\\ny „pp¨|x, cq, (1)\\nalong with the sequence of n retrieved contexts\\nc “ rc1; c2; ¨¨¨ ; cns. Then, for a training triplet\\npx, c, ˆyqthe negative log-likelihood (NLL) loss for\\nmaximum likelihood estimation training is\\nLn “´\\nÿ\\nt\\nlog ppˆyt |x, c, ˆyătq, (2)\\nwhich encourages the model to produce the correct\\nanswer ˆy given the input x and retrieved contexts.\\nInspired by An et al. (2024), referred to as IN2,\\nwe employ position perturbation to augmentc from\\nthe corpus C with c1. For comparison, IN2 synthe-\\nsized question and context pq, cqpairs where the\\ngold passage s for generating the gold answer ˆy\\nappears in various positions. As Figure 2 shows,\\nwe retain both the original pq, c, ˆyqand the per-\\nturbed examples pq, c1, ˆyq: Unlike IN2’s using c1\\nonly for training (orange arrows), we train over the\\naugmented dataset C1which includes both c and c1\\n(blue arrows). Predictions for both are supervised\\nto converge to the same ground-truth ˆy using the\\nloss in Eq 2.\\nSecond, by adding a distill loss, we can further\\nmatch token-level output probability distributions\\nfor c and c1. We use the sum of Jensen-Shannon\\nDivergence (JSD) between output probability dis-\\ntributions at each time step t for this purpose:2\\nLd “\\nÿ\\nt\\nJSD\\n`\\nftpcq}ftpc1q\\n˘\\n, (3)\\nwhere ftpcq “ppˆyt |x, c, ˆyătq. This encourages\\nthe model to align its internal representations of in-\\nput and association with the output, encoded in the\\n‘dark knowledge’ (Hinton et al., 2015; Sadowski\\net al., 2015; Furlanello et al., 2018) across different\\nperturbations.\\nFinally, the two types of loss in Eq 2 and 3 can\\nbe combined to obtain our training objective:\\nL “Ln `λ ¨Ld, (4)\\nwhere the hyperparameter λ determines the relative\\nstrength of the two terms.\\n2.2 RD: Adaptive teacher selection for rank\\ndistillation\\nHowever, as previously outlined in Table 1A, dis-\\ntill loss on a random perturbation c1 may inter-\\nfere with the RD objective in an RAG scenario\\nwhere retriever provides a meaningful ranking c\\nwith valuable prior: In this work, we consider MS\\nMARCO (Bajaj et al., 2018) as a representative ex-\\nample, where an industry-scale complex retrieval\\nsystem provides the ranking.\\nFigure 3A depicts such unlearning of ranker\\nprior, when distilled from a random perturbation\\nin scenario A. The y-axis in the plot represents the\\nprobability the LLM assigns to the ground-truth an-\\nswer, ppˆy |x, cqfor the given order c (solid circle)\\n2While we default to summing all terms, the number of\\ntime steps t to aggregate in Eq 3 can be adjusted for efficiency,\\nas detailed in Appendix C.\\n2'), Document(metadata={'page': 5, 'source': '/content/rag_doc.pdf'}, page_content='A Related Work\\nA.1 Position bias in long context LLM\\nLiu et al. (2024) and similar works have shown that\\nLLMs favor input contexts placed at the beginning\\nor end of the input, a tendency that benchmarks\\nlike needle-in-a-haystack4 aim to assess by testing\\ntheir ability to locate relevant information (‘nee-\\ndle’) within long, potentially irrelevant contexts\\n(‘haystack’). An et al. (2024) extended this un-\\nderstanding by training models on synthetic data,\\nintentionally perturbing a position of gold segment\\nand adding random noises. Similarly, Fu et al.\\n(2024) examined continual pretraining of LLMs\\non long-context data to expand their context win-\\ndow size for retrieving information.\\nOur distinction is to use position perturbation\\nfor a different objective of data augmentation for\\nconsistency training.\\nA.2 Data augmentation for consistency\\nPairing a datapoint with a counterfactual applying\\na small perturbation has been mainly studied for\\nrobust training on simpler tasks such as classifica-\\ntion (Xie et al., 2020). To our knowledge, we are\\nthe first to augment a position-perturbed retriever\\nduring training and enforce consistency for RAG.\\nAnother related line of work is interpolating\\ntwo training instances (Chuang and Mroueh, 2021),\\nwhich we extend to define a space of controlled per-\\nturbations for dynamic adaptation in Section 2.2.\\nB Implementation Details\\nMN construction For MN data construction, we\\ngenerally followed the recipe from An et al. (2024),\\nwith the subtle difference that Mixtral was used for\\nquestion and answer generation. When preparing\\nthe MN dataset following An et al. (2024), we gen-\\nerally abide by their practices, while using Mixtral\\nas the LLM for question and answer extraction, and\\nemployed GPT-4 to verify it. For the seed corpus,\\nwe utilized the same realnewslike subset from\\nthe C4 corpus as C. We refer the reader to their\\noriginal paper for more details.\\nIn addition, to study how LLMs can be trained\\nto refuse to answer when there are insufficient evi-\\ndence provided, rather than to hallucinate, we split\\nthe test set into two settings, answerable and unan-\\nswerable: In the latter, dubbed MN-IDK, the gold\\nsegment s that provides the evidence to answer the\\n4github.com/gkamradt/LLMTest_NeedleInAHaystack\\ngiven question is omitted. Thus, the model is ex-\\npected to answer it does not have enough evidence\\nin the contexts to provide the correct answer, or, ‘I\\ndon’t know.’\\nMetrics The evaluation protocol involving GPT-\\n4 as the judge from Yang et al. (2024) evaluates\\nthe correctness of the answer with greater flexibil-\\nity, compared to the canonical lexical match based\\nmetrics, and is known to align better with human\\njudgment. Also, it penalizes hallucinated response\\nmore than simply abstaining.\\nWhile other benchmarks considered in this work\\nrequire shorter answers, expected answers in MN\\nand MN-IDK typically comprise of a few sentences:\\nthus, we report sentence-level F1 score for MN,\\nwhere GPT-4 was used as a judge in the same man-\\nner as the method described above to decide each\\nsentence in the generated answer is supported by\\nthe ground-truth (precision), and vice versa (re-\\ncall). For MN-IDK, GPT-4 determined whether the\\nmodel response successfully refused to provide the\\nanswer or not, and we reported the accuracy.\\nTraining For MS MARCO, HotpotQA and MN,\\nwe finetuned Phi-3 3B model on their respective\\ntrain data: for MS MARCO, we used 20k examples\\nheld out from v2.1 dev set for training, and used\\nnon-overlapping subset for testing.\\nFor training with CORD on MN, as described in\\nSection 2.2, we generated an artificial ranking over\\nthe passages by reranking them with a ColBERT\\nvariant model from Jina AI,56 which also provided\\nscores for each passage. This artificial ranking\\nserves as the opposite extreme of the interpolated\\nperturbation space, c1.\\nThe base model, Phi-3 3B, was trained with\\nLoRA at bf16 precision. The relevant hyperparame-\\nter configuration was as follows: for LoRA related\\nsettings, we used rank of r “ 8, α “ 32, and\\ndropout rate of 0.1. For general configuration, we\\nused linear decay for scheduling with initial learn-\\ning rate of 1e-4 and effective batch size of 4; we\\ntrained the model for 5 epochs with weight decay\\nof 0.01 applied. For CORD -specific configuration,\\nwe set coefficient for consistency loss strength λ as\\n10 and the noise degree for interpolating contexts\\nα as 0.5 throughout our experiments. We leave it\\nas future efforts to search for optimal configuration\\n5huggingface.co/jinaai/jina-colbert-v2\\n6While our work is completely orthogonal to the choice\\nof retriever, we chose this lightweight model that reportedly\\nperform well across several IR benchmarks (Jha et al., 2024).\\n6'), Document(metadata={'page': 4, 'source': '/content/rag_doc.pdf'}, page_content='Limitations\\nWhether our findings generalize over diverse mod-\\nels can be further explored. In addition, the pros\\nand cons of diverse mixing strategies for an inter-\\npolated sample space, such as employing another\\nretriever for mix, can be explored; we leave it as\\nfuture work.\\nReferences\\nShengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng,\\nand Jian-Guang Lou. 2024. Make your llm fully\\nutilize the context. Preprint, arXiv:2404.16811.\\nPayal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\\nJianfeng Gao, Xiaodong Liu, Rangan Majumder,\\nAndrew McNamara, Bhaskar Mitra, Tri Nguyen,\\nMir Rosenberg, Xia Song, Alina Stoica, Saurabh\\nTiwary, and Tong Wang. 2018. Ms marco: A human\\ngenerated machine reading comprehension dataset.\\nPreprint, arXiv:1611.09268.\\nChing-Yao Chuang and Youssef Mroueh. 2021. Fair\\nmixup: Fairness via interpolation. In 9th Inter-\\nnational Conference on Learning Representations,\\nICLR 2021, Virtual Event, Austria, May 3-7, 2021 .\\nOpenReview.net.\\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\\nData engineering for scaling language models to 128k\\ncontext. In Forty-first International Conference on\\nMachine Learning, ICML 2024, Vienna, Austria, July\\n21-27, 2024. OpenReview.net.\\nTommaso Furlanello, Zachary Lipton, Michael Tschan-\\nnen, Laurent Itti, and Anima Anandkumar. 2018.\\nBorn again neural networks. In Proceedings of the\\n35th International Conference on Machine Learn-\\ning, volume 80 of Proceedings of Machine Learning\\nResearch, pages 1607–1616. PMLR.\\nGeoffrey Hinton, Oriol Vinyals, and Jeffrey Dean. 2015.\\nDistilling the knowledge in a neural network. In\\nNIPS Deep Learning and Representation Learning\\nWorkshop.\\nE. T. Jaynes. 1957. Information theory and statistical\\nmechanics. Phys. Rev., 106:620–630.\\nRohan Jha, Bo Wang, Michael Günther, Saba Sturua,\\nMohammad Kalim Akram, and Han Xiao. 2024.\\nJina-colbert-v2: A general-purpose multilingual late\\ninteraction retriever. CoRR, abs/2408.16672.\\nTom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\\nfield, Michael Collins, Ankur Parikh, Chris Alberti,\\nDanielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\\nton Lee, Kristina Toutanova, Llion Jones, Matthew\\nKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\\nUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\\nral questions: A benchmark for question answering\\nresearch. Transactions of the Association for Compu-\\ntational Linguistics, 7:452–466.\\nBill Yuchen Lin, Abhilasha Ravichander, Ximing Lu,\\nNouha Dziri, Melanie Sclar, Khyathi Chandu, Chan-\\ndra Bhagavatula, and Yejin Choi. 2024. The unlock-\\ning spell on base llms: Rethinking alignment via\\nin-context learning. In International Conference on\\nLearning Representations.\\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\\njape, Michele Bevilacqua, Fabio Petroni, and Percy\\nLiang. 2024. Lost in the middle: How language mod-\\nels use long contexts. Transactions of the Association\\nfor Computational Linguistics, 12:157–173.\\nPeter Sadowski, Julian Collado, Daniel Whiteson, and\\nPierre Baldi. 2015. Deep learning, dark knowl-\\nedge, and dark matter. In Proceedings of the NIPS\\n2014 Workshop on High-energy Physics and Ma-\\nchine Learning, volume 42 of Proceedings of Ma-\\nchine Learning Research , pages 81–87, Montreal,\\nCanada. PMLR.\\nQizhe Xie, Zihang Dai, Eduard H. Hovy, Thang Luong,\\nand Quoc Le. 2020. Unsupervised data augmenta-\\ntion for consistency training. In Advances in Neural\\nInformation Processing Systems 33: Annual Confer-\\nence on Neural Information Processing Systems 2020,\\nNeurIPS 2020, December 6-12, 2020, virtual.\\nXiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla,\\nXiangsen Chen, Sajal Choudhary, Rongze Daniel\\nGui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong,\\nBrian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan,\\nChenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang,\\nLei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah,\\nRakesh Wanga, Anuj Kumar, Wen-tau Yih, and\\nXin Luna Dong. 2024. CRAG - comprehensive RAG\\nbenchmark. CoRR, abs/2406.04744.\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\\nWilliam Cohen, Ruslan Salakhutdinov, and Christo-\\npher D. Manning. 2018. HotpotQA: A dataset for\\ndiverse, explainable multi-hop question answering.\\nIn Proceedings of the 2018 Conference on Empiri-\\ncal Methods in Natural Language Processing, pages\\n2369–2380, Brussels, Belgium. Association for Com-\\nputational Linguistics.\\n5')]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"result\"])"
      ],
      "metadata": {
        "id": "qsEIKYL0PwR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d55caa-d267-4751-ae9b-a8f37dbe8fe5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG stands for Retrieval-Augmented Generation. It is a type of natural language processing (NLP) model that combines the strengths of retrieval-based and generation-based approaches to answer questions or generate text.\n",
            "\n",
            "In a RAG model, the input is first passed through a retriever, which retrieves a set of relevant contexts or passages from a large corpus of text. The retriever is typically a neural network-based model that is trained to rank the passages based on their relevance to the input.\n",
            "\n",
            "The retrieved passages are then passed through a generator, which is another neural network-based model that generates the final output text based on the input and the retrieved passages. The generator can be a language model, a machine translation model, or any other type of text generation model.\n",
            "\n",
            "The key idea behind RAG is to leverage the strengths of both retrieval-based and generation-based approaches. Retrieval-based approaches are good at finding relevant information, but they can struggle to generate coherent and fluent text. Generation-based approaches, on the other hand, can generate coherent and fluent text, but they can struggle to find relevant information.\n",
            "\n",
            "By combining the two approaches, RAG models can generate high-quality text that is both relevant and coherent. RAG has been applied to a variety of NLP tasks, including question answering, text summarization, and dialogue generation.\n",
            "\n",
            "In the context of the provided PDF, RAG is used to evaluate the performance of the proposed CORD (Consistency and Rank Distillation) method, which is a training objective for RAG models that aims to improve their performance by regularizing the output consistency over possible perturbations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the response contains 'source_documents' and 'metadata' attributes\n",
        "# Print the source document's metadata for the first source document\n",
        "print(response[\"source_documents\"][0].metadata[\"source\"])\n"
      ],
      "metadata": {
        "id": "bXjV5NjhQZnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a6ec28-8c8c-49a1-82ed-34051fae8536"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rag_doc.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the QA chain and get a response for the user query\n",
        "query = \"Give me summary about RAG from this pdf?\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "# Print the result of the query (summary or answer)\n",
        "print(response[\"result\"])\n",
        "\n",
        "# Print a separator for clarity\n",
        "print(\"*\"*30)\n",
        "\n",
        "# Print the source document metadata (source)\n",
        "print(\"Source Document:\", response[\"source_documents\"][0].metadata[\"source\"])"
      ],
      "metadata": {
        "id": "A6fO_4ndQZqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a9736c-da20-4b80-a79e-1cdd1f032118"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text, here is a summary about RAG (Retrieval-Augmented Generation):\n",
            "\n",
            "RAG is a task that involves generating an answer to a question based on a set of retrieved contexts. The model takes an input question and a sequence of retrieved contexts, and generates an answer. The goal of RAG is to balance two objectives: \n",
            "\n",
            "1. Consistency (CO): The model should be able to generate consistent answers across different perturbations of the retrieved contexts.\n",
            "2. Rank Distillation (RD): The model should be able to distill the valuable prior knowledge from the retriever, which provides a ranking of the contexts.\n",
            "\n",
            "The text proposes a method called CORD, which aims to balance these two objectives by augmenting the training data with perturbed contexts and using a distillation loss to regularize the model. CORD also adaptively chooses the degree of perturbation to prevent unlearning the valuable prior knowledge from the retriever. The method is evaluated on several QA benchmarks, including MS MARCO, HotpotQA, and NaturalQuestions, and shows promising results.\n",
            "******************************\n",
            "Source Document: /content/rag_doc.pdf\n"
          ]
        }
      ]
    }
  ]
}